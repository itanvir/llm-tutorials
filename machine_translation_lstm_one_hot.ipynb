{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18585aba-1f54-4ae6-ba33-23b66161968c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "seed = 50\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1079f67b-7de4-47c8-aa32-625f2d9009fc",
   "metadata": {},
   "source": [
    "## LSTM example: Machine translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fc612d-3ed8-4fdf-9208-bcbb06ebd32c",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7f91657-8598-4ea4-821b-3777c417ad5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from num2words import num2words\n",
    "\n",
    "def create_french_to_english_data():\n",
    "    start = 1\n",
    "    end = 1000\n",
    "    \n",
    "    # Create the dataset\n",
    "    source = []\n",
    "    target = []\n",
    "    for i in range(start, end+1):\n",
    "        # Convert the number to words in French\n",
    "        words = '<start> ' + num2words(i, lang='fr') + ' <end>'\n",
    "        source.append(words)\n",
    "        words = '<start> ' + num2words(i, lang='en') + ' <end>'\n",
    "        target.append(words)\n",
    "    \n",
    "    return source, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a88ef316-6564-4a68-b023-fb8541aa3651",
   "metadata": {},
   "outputs": [],
   "source": [
    "source, target = create_french_to_english_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf2df79f-00b5-49bd-b16b-fa3d0c6f2b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(source, target):\n",
    "\n",
    "    train_source, test_source, train_target, test_target = train_test_split(\n",
    "        source, target, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    return train_source, test_source, train_target, test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "034b4ceb-27de-47d6-9db4-056b79169bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_source, test_source, train_target, test_target = split_data(source, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076c9a7e-7fd0-49e2-a939-662829335aba",
   "metadata": {},
   "source": [
    "### Prepare sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec7402d7-e358-4685-be35-b8c8c004cc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(oov_token=\"<OOV>\", filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n",
    "tokenizer.fit_on_texts(train_source + train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c3422fe-88f9-47a1-a24c-049190e98f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def prepare_sequences(source, target, tokenizer):\n",
    "    \"\"\"\n",
    "    Prepare the input and output sequences for training the model.\n",
    "\n",
    "    Parameters:\n",
    "    dataset (list): The dataset to be processed.\n",
    "    tokenizer (Tokenizer): The tokenizer to be used.\n",
    "\n",
    "    Returns:\n",
    "    tuple: The prepared input and output sequences.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    X_encoder = tokenizer.texts_to_sequences(source)\n",
    "\n",
    "    Y_encoded = tokenizer.texts_to_sequences(target)\n",
    "    Y_decoder_input = Y_encoded\n",
    "    Y_decoder_output = [encoded[1:] + [0] for encoded in Y_encoded]\n",
    "    \n",
    "    X_encoder = pad_sequences(X_encoder, maxlen=8, padding='post', truncating='post', dtype='float32')\n",
    "    Y_decoder_input = pad_sequences(Y_decoder_input, maxlen=8, padding='post', truncating='post', dtype='float32')\n",
    "    Y_decoder_output = pad_sequences(Y_decoder_output, maxlen=8, padding='post', truncating='post', dtype='float32')\n",
    "\n",
    "    return X_encoder, Y_decoder_input, Y_decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82e55b67-a15b-4492-bb66-828efb770923",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_encoder, Y_train_decoder_input, Y_train_decoder_output = prepare_sequences(train_source, train_target, tokenizer)\n",
    "X_test_encoder, Y_test_decoder_input, Y_test_decoder_output = prepare_sequences(test_source, test_target, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8be356c2-6533-486f-a5be-3cd3c49e435b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, CategoryEncoding, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def create_lstm_encoder_decoder_model(encoder_vocab_size, decoder_vocab_size, embedding_dim, seq_length):\n",
    "\n",
    "    # Encoder\n",
    "    encoder_inputs = Input(shape=(seq_length, encoder_vocab_size), name='encoder_inputs')\n",
    "    #encoder_embedding = TimeDistributed(CategoryEncoding(num_tokens=encoder_vocab_size, output_mode = \"one_hot\"))(encoder_inputs)\n",
    "    encoder_lstm, state_h, state_c = LSTM(units=lstm_units, return_state=True, name='encoder_lstm')(encoder_inputs)\n",
    "    encoder_states = [state_h, state_c]\n",
    "    \n",
    "    # Decoder\n",
    "    decoder_inputs = Input(shape=(seq_length, decoder_vocab_size), name='decoder_inputs')\n",
    "    #decoder_embedding = TimeDistributed(CategoryEncoding(num_tokens=encoder_vocab_size, output_mode = \"one_hot\"))(decoder_inputs)\n",
    "    decoder_lstm, _, _ = LSTM(\n",
    "        units=lstm_units, return_sequences=True, return_state=True, name=\"decoder_lstm\"\n",
    "    )(decoder_inputs, initial_state=encoder_states)\n",
    "    decoder_dense = Dense(units=decoder_vocab_size, activation='softmax', name='decoder_dense')\n",
    "    decoder_outputs = decoder_dense(decoder_lstm)\n",
    "    \n",
    "    # Model\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Display the model summary\n",
    "    model.summary(line_length=120)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e36522f1-ad5c-4afd-a0e2-e3ca4104e052",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 20:53:01.519810: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Max\n",
      "2024-06-12 20:53:01.519832: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 64.00 GB\n",
      "2024-06-12 20:53:01.519838: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 24.00 GB\n",
      "2024-06-12 20:53:01.519862: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-06-12 20:53:01.519875: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "________________________________________________________________________________________________________________________\n",
      " Layer (type)                       Output Shape                        Param #     Connected to                        \n",
      "========================================================================================================================\n",
      " encoder_inputs (InputLayer)        [(None, 8, 59)]                     0           []                                  \n",
      "                                                                                                                        \n",
      " decoder_inputs (InputLayer)        [(None, 8, 59)]                     0           []                                  \n",
      "                                                                                                                        \n",
      " encoder_lstm (LSTM)                [(None, 512),                       1171456     ['encoder_inputs[0][0]']            \n",
      "                                     (None, 512),                                                                       \n",
      "                                     (None, 512)]                                                                       \n",
      "                                                                                                                        \n",
      " decoder_lstm (LSTM)                [(None, 8, 512),                    1171456     ['decoder_inputs[0][0]',            \n",
      "                                     (None, 512),                                    'encoder_lstm[0][1]',              \n",
      "                                     (None, 512)]                                    'encoder_lstm[0][2]']              \n",
      "                                                                                                                        \n",
      " decoder_dense (Dense)              (None, 8, 59)                       30267       ['decoder_lstm[0][0]']              \n",
      "                                                                                                                        \n",
      "========================================================================================================================\n",
      "Total params: 2373179 (9.05 MB)\n",
      "Trainable params: 2373179 (9.05 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Assuming vocabulary sizes are known\n",
    "encoder_vocab_size = 59  # Change this to your actual encoder vocabulary size\n",
    "decoder_vocab_size = 59  # Change this to your actual decoder vocabulary size\n",
    "embedding_dim = 256  # Dimension of the embedding vectors\n",
    "lstm_units = 512  # Number of LSTM units\n",
    "seq_length = 8  # Sequence length for both encoder and decoder\n",
    "\n",
    "model = create_lstm_encoder_decoder_model(encoder_vocab_size, decoder_vocab_size, embedding_dim, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffe4c887-1842-46e3-a49f-7c2c5b0e75c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_encoder = to_categorical(X_train_encoder, num_classes=len(tokenizer.word_index)+1)\n",
    "Y_train_decoder_input = to_categorical(Y_train_decoder_input, num_classes=len(tokenizer.word_index)+1)\n",
    "Y_train_decoder_output = to_categorical(Y_train_decoder_output, num_classes=len(tokenizer.word_index)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a38effa6-3cbd-497e-9e3b-65b1cd0f4c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 8, 59)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_decoder_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab319d31-32db-44c5-8208-2984b3dc445f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 20:53:02.960943: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 70ms/step - loss: 3.3823 - accuracy: 0.2936 - val_loss: 2.3479 - val_accuracy: 0.4430\n",
      "Epoch 2/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 2.2554 - accuracy: 0.4922 - val_loss: 1.9528 - val_accuracy: 0.5336\n",
      "Epoch 3/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.8290 - accuracy: 0.5461 - val_loss: 1.7343 - val_accuracy: 0.6211\n",
      "Epoch 4/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.6365 - accuracy: 0.5934 - val_loss: 1.5272 - val_accuracy: 0.5859\n",
      "Epoch 5/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.4191 - accuracy: 0.6137 - val_loss: 1.2502 - val_accuracy: 0.6477\n",
      "Epoch 6/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 1.1335 - accuracy: 0.6604 - val_loss: 1.0429 - val_accuracy: 0.6719\n",
      "Epoch 7/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.9899 - accuracy: 0.6764 - val_loss: 0.9537 - val_accuracy: 0.6812\n",
      "Epoch 8/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.9251 - accuracy: 0.6875 - val_loss: 0.9535 - val_accuracy: 0.6773\n",
      "Epoch 9/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8698 - accuracy: 0.6992 - val_loss: 0.8788 - val_accuracy: 0.6898\n",
      "Epoch 10/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.8400 - accuracy: 0.7029 - val_loss: 0.8255 - val_accuracy: 0.7078\n",
      "Epoch 11/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8091 - accuracy: 0.7180 - val_loss: 0.8254 - val_accuracy: 0.7102\n",
      "Epoch 12/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.7919 - accuracy: 0.7207 - val_loss: 0.8028 - val_accuracy: 0.7102\n",
      "Epoch 13/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.7940 - accuracy: 0.7197 - val_loss: 0.8010 - val_accuracy: 0.7250\n",
      "Epoch 14/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.8202 - accuracy: 0.7156 - val_loss: 0.7916 - val_accuracy: 0.7102\n",
      "Epoch 15/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.7716 - accuracy: 0.7203 - val_loss: 0.7732 - val_accuracy: 0.7281\n",
      "Epoch 16/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.7358 - accuracy: 0.7344 - val_loss: 0.7497 - val_accuracy: 0.7453\n",
      "Epoch 17/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.7112 - accuracy: 0.7395 - val_loss: 0.7434 - val_accuracy: 0.7328\n",
      "Epoch 18/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.6923 - accuracy: 0.7482 - val_loss: 0.7288 - val_accuracy: 0.7563\n",
      "Epoch 19/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.6685 - accuracy: 0.7641 - val_loss: 0.7131 - val_accuracy: 0.7609\n",
      "Epoch 20/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.6520 - accuracy: 0.7736 - val_loss: 0.6975 - val_accuracy: 0.7773\n",
      "Epoch 21/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6325 - accuracy: 0.7744 - val_loss: 0.6846 - val_accuracy: 0.7742\n",
      "Epoch 22/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.6135 - accuracy: 0.7861 - val_loss: 0.6624 - val_accuracy: 0.7992\n",
      "Epoch 23/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.5883 - accuracy: 0.7928 - val_loss: 0.6501 - val_accuracy: 0.7883\n",
      "Epoch 24/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5565 - accuracy: 0.8139 - val_loss: 0.6259 - val_accuracy: 0.8125\n",
      "Epoch 25/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.5174 - accuracy: 0.8275 - val_loss: 0.5676 - val_accuracy: 0.8109\n",
      "Epoch 26/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4764 - accuracy: 0.8350 - val_loss: 0.5284 - val_accuracy: 0.8227\n",
      "Epoch 27/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.4430 - accuracy: 0.8436 - val_loss: 0.5307 - val_accuracy: 0.8203\n",
      "Epoch 28/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.4369 - accuracy: 0.8455 - val_loss: 0.4886 - val_accuracy: 0.8359\n",
      "Epoch 29/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.4039 - accuracy: 0.8576 - val_loss: 0.4710 - val_accuracy: 0.8383\n",
      "Epoch 30/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.3847 - accuracy: 0.8602 - val_loss: 0.4850 - val_accuracy: 0.8422\n",
      "Epoch 31/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3701 - accuracy: 0.8742 - val_loss: 0.4392 - val_accuracy: 0.8578\n",
      "Epoch 32/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.3572 - accuracy: 0.8732 - val_loss: 0.4444 - val_accuracy: 0.8445\n",
      "Epoch 33/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.3153 - accuracy: 0.8955 - val_loss: 0.3876 - val_accuracy: 0.8672\n",
      "Epoch 34/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.2821 - accuracy: 0.9090 - val_loss: 0.3685 - val_accuracy: 0.8758\n",
      "Epoch 35/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.2463 - accuracy: 0.9223 - val_loss: 0.3339 - val_accuracy: 0.8859\n",
      "Epoch 36/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.2205 - accuracy: 0.9363 - val_loss: 0.2976 - val_accuracy: 0.8984\n",
      "Epoch 37/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.1877 - accuracy: 0.9477 - val_loss: 0.2566 - val_accuracy: 0.9203\n",
      "Epoch 38/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.1649 - accuracy: 0.9578 - val_loss: 0.2498 - val_accuracy: 0.9141\n",
      "Epoch 39/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.1606 - accuracy: 0.9559 - val_loss: 0.2474 - val_accuracy: 0.9195\n",
      "Epoch 40/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.1960 - accuracy: 0.9453 - val_loss: 0.2832 - val_accuracy: 0.9062\n",
      "Epoch 41/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.1745 - accuracy: 0.9510 - val_loss: 0.2244 - val_accuracy: 0.9328\n",
      "Epoch 42/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.1220 - accuracy: 0.9736 - val_loss: 0.1907 - val_accuracy: 0.9414\n",
      "Epoch 43/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0880 - accuracy: 0.9830 - val_loss: 0.1518 - val_accuracy: 0.9594\n",
      "Epoch 44/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0669 - accuracy: 0.9912 - val_loss: 0.1400 - val_accuracy: 0.9586\n",
      "Epoch 45/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0517 - accuracy: 0.9939 - val_loss: 0.1269 - val_accuracy: 0.9633\n",
      "Epoch 46/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0413 - accuracy: 0.9973 - val_loss: 0.1069 - val_accuracy: 0.9711\n",
      "Epoch 47/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0330 - accuracy: 0.9979 - val_loss: 0.0931 - val_accuracy: 0.9797\n",
      "Epoch 48/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0268 - accuracy: 0.9988 - val_loss: 0.0837 - val_accuracy: 0.9758\n",
      "Epoch 49/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0224 - accuracy: 0.9992 - val_loss: 0.0806 - val_accuracy: 0.9797\n",
      "Epoch 50/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0196 - accuracy: 0.9992 - val_loss: 0.0709 - val_accuracy: 0.9836\n",
      "Epoch 51/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0169 - accuracy: 0.9994 - val_loss: 0.0685 - val_accuracy: 0.9828\n",
      "Epoch 52/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0151 - accuracy: 0.9996 - val_loss: 0.0695 - val_accuracy: 0.9828\n",
      "Epoch 53/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0142 - accuracy: 0.9996 - val_loss: 0.0625 - val_accuracy: 0.9844\n",
      "Epoch 54/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0125 - accuracy: 0.9996 - val_loss: 0.0599 - val_accuracy: 0.9852\n",
      "Epoch 55/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0115 - accuracy: 0.9996 - val_loss: 0.0567 - val_accuracy: 0.9852\n",
      "Epoch 56/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0101 - accuracy: 0.9996 - val_loss: 0.0539 - val_accuracy: 0.9883\n",
      "Epoch 57/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0094 - accuracy: 0.9996 - val_loss: 0.0542 - val_accuracy: 0.9867\n",
      "Epoch 58/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0086 - accuracy: 0.9996 - val_loss: 0.0542 - val_accuracy: 0.9867\n",
      "Epoch 59/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0079 - accuracy: 0.9996 - val_loss: 0.0493 - val_accuracy: 0.9891\n",
      "Epoch 60/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0072 - accuracy: 0.9996 - val_loss: 0.0466 - val_accuracy: 0.9898\n",
      "Epoch 61/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0067 - accuracy: 0.9996 - val_loss: 0.0469 - val_accuracy: 0.9891\n",
      "Epoch 62/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0063 - accuracy: 0.9996 - val_loss: 0.0465 - val_accuracy: 0.9883\n",
      "Epoch 63/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0060 - accuracy: 0.9996 - val_loss: 0.0458 - val_accuracy: 0.9891\n",
      "Epoch 64/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0056 - accuracy: 0.9998 - val_loss: 0.0452 - val_accuracy: 0.9883\n",
      "Epoch 65/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0054 - accuracy: 0.9998 - val_loss: 0.0450 - val_accuracy: 0.9906\n",
      "Epoch 66/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0050 - accuracy: 0.9998 - val_loss: 0.0440 - val_accuracy: 0.9891\n",
      "Epoch 67/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0048 - accuracy: 0.9998 - val_loss: 0.0412 - val_accuracy: 0.9906\n",
      "Epoch 68/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 0.9898\n",
      "Epoch 69/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0415 - val_accuracy: 0.9891\n",
      "Epoch 70/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9898\n",
      "Epoch 71/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0408 - val_accuracy: 0.9898\n",
      "Epoch 72/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0405 - val_accuracy: 0.9898\n",
      "Epoch 73/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9906\n",
      "Epoch 74/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9914\n",
      "Epoch 75/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0378 - val_accuracy: 0.9898\n",
      "Epoch 76/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0379 - val_accuracy: 0.9906\n",
      "Epoch 77/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0362 - val_accuracy: 0.9914\n",
      "Epoch 78/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0360 - val_accuracy: 0.9922\n",
      "Epoch 79/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0358 - val_accuracy: 0.9930\n",
      "Epoch 80/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0358 - val_accuracy: 0.9914\n",
      "Epoch 81/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0360 - val_accuracy: 0.9922\n",
      "Epoch 82/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0343 - val_accuracy: 0.9922\n",
      "Epoch 83/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0342 - val_accuracy: 0.9922\n",
      "Epoch 84/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0338 - val_accuracy: 0.9930\n",
      "Epoch 85/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0343 - val_accuracy: 0.9914\n",
      "Epoch 86/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0338 - val_accuracy: 0.9930\n",
      "Epoch 87/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0328 - val_accuracy: 0.9922\n",
      "Epoch 88/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0335 - val_accuracy: 0.9930\n",
      "Epoch 89/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0322 - val_accuracy: 0.9930\n",
      "Epoch 90/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0329 - val_accuracy: 0.9914\n",
      "Epoch 91/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0321 - val_accuracy: 0.9930\n",
      "Epoch 92/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0317 - val_accuracy: 0.9930\n",
      "Epoch 93/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0317 - val_accuracy: 0.9930\n",
      "Epoch 94/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0320 - val_accuracy: 0.9930\n",
      "Epoch 95/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0308 - val_accuracy: 0.9930\n",
      "Epoch 96/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0310 - val_accuracy: 0.9930\n",
      "Epoch 97/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0305 - val_accuracy: 0.9930\n",
      "Epoch 98/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0311 - val_accuracy: 0.9922\n",
      "Epoch 99/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0306 - val_accuracy: 0.9930\n",
      "Epoch 100/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0306 - val_accuracy: 0.9930\n",
      "Epoch 101/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0297 - val_accuracy: 0.9930\n",
      "Epoch 102/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0302 - val_accuracy: 0.9930\n",
      "Epoch 103/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0295 - val_accuracy: 0.9930\n",
      "Epoch 104/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0297 - val_accuracy: 0.9930\n",
      "Epoch 105/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0289 - val_accuracy: 0.9930\n",
      "Epoch 106/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0295 - val_accuracy: 0.9930\n",
      "Epoch 107/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0288 - val_accuracy: 0.9930\n",
      "Epoch 108/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 9.8690e-04 - accuracy: 1.0000 - val_loss: 0.0292 - val_accuracy: 0.9922\n",
      "Epoch 109/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 9.6335e-04 - accuracy: 1.0000 - val_loss: 0.0285 - val_accuracy: 0.9930\n",
      "Epoch 110/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 9.4183e-04 - accuracy: 1.0000 - val_loss: 0.0288 - val_accuracy: 0.9922\n",
      "Epoch 111/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 9.2259e-04 - accuracy: 1.0000 - val_loss: 0.0285 - val_accuracy: 0.9930\n",
      "Epoch 112/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 8.9944e-04 - accuracy: 1.0000 - val_loss: 0.0283 - val_accuracy: 0.9937\n",
      "Epoch 113/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 8.8120e-04 - accuracy: 1.0000 - val_loss: 0.0280 - val_accuracy: 0.9930\n",
      "Epoch 114/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 8.6084e-04 - accuracy: 1.0000 - val_loss: 0.0286 - val_accuracy: 0.9930\n",
      "Epoch 115/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 8.4436e-04 - accuracy: 1.0000 - val_loss: 0.0274 - val_accuracy: 0.9930\n",
      "Epoch 116/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 8.2734e-04 - accuracy: 1.0000 - val_loss: 0.0285 - val_accuracy: 0.9930\n",
      "Epoch 117/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 8.0811e-04 - accuracy: 1.0000 - val_loss: 0.0272 - val_accuracy: 0.9937\n",
      "Epoch 118/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 7.9195e-04 - accuracy: 1.0000 - val_loss: 0.0279 - val_accuracy: 0.9930\n",
      "Epoch 119/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 7.7650e-04 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 0.9930\n",
      "Epoch 120/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 7.5985e-04 - accuracy: 1.0000 - val_loss: 0.0271 - val_accuracy: 0.9937\n",
      "Epoch 121/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 7.4455e-04 - accuracy: 1.0000 - val_loss: 0.0276 - val_accuracy: 0.9930\n",
      "Epoch 122/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 7.3115e-04 - accuracy: 1.0000 - val_loss: 0.0273 - val_accuracy: 0.9945\n",
      "Epoch 123/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 7.1565e-04 - accuracy: 1.0000 - val_loss: 0.0269 - val_accuracy: 0.9937\n",
      "Epoch 124/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 7.0199e-04 - accuracy: 1.0000 - val_loss: 0.0265 - val_accuracy: 0.9922\n",
      "Epoch 125/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 6.8665e-04 - accuracy: 1.0000 - val_loss: 0.0266 - val_accuracy: 0.9930\n",
      "Epoch 126/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 6.7465e-04 - accuracy: 1.0000 - val_loss: 0.0270 - val_accuracy: 0.9930\n",
      "Epoch 127/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 6.6207e-04 - accuracy: 1.0000 - val_loss: 0.0266 - val_accuracy: 0.9945\n",
      "Epoch 128/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 6.5000e-04 - accuracy: 1.0000 - val_loss: 0.0262 - val_accuracy: 0.9930\n",
      "Epoch 129/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 6.3758e-04 - accuracy: 1.0000 - val_loss: 0.0269 - val_accuracy: 0.9922\n",
      "Epoch 130/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 6.2704e-04 - accuracy: 1.0000 - val_loss: 0.0263 - val_accuracy: 0.9937\n",
      "Epoch 131/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 6.1517e-04 - accuracy: 1.0000 - val_loss: 0.0264 - val_accuracy: 0.9937\n",
      "Epoch 132/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 6.0405e-04 - accuracy: 1.0000 - val_loss: 0.0265 - val_accuracy: 0.9945\n",
      "Epoch 133/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 5.9304e-04 - accuracy: 1.0000 - val_loss: 0.0260 - val_accuracy: 0.9937\n",
      "Epoch 134/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 5.8355e-04 - accuracy: 1.0000 - val_loss: 0.0259 - val_accuracy: 0.9930\n",
      "Epoch 135/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 5.7360e-04 - accuracy: 1.0000 - val_loss: 0.0258 - val_accuracy: 0.9930\n",
      "Epoch 136/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 5.6476e-04 - accuracy: 1.0000 - val_loss: 0.0261 - val_accuracy: 0.9930\n",
      "Epoch 137/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 5.5384e-04 - accuracy: 1.0000 - val_loss: 0.0258 - val_accuracy: 0.9937\n",
      "Epoch 138/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 5.4455e-04 - accuracy: 1.0000 - val_loss: 0.0257 - val_accuracy: 0.9937\n",
      "Epoch 139/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 5.3472e-04 - accuracy: 1.0000 - val_loss: 0.0258 - val_accuracy: 0.9930\n",
      "Epoch 140/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 5.2640e-04 - accuracy: 1.0000 - val_loss: 0.0257 - val_accuracy: 0.9930\n",
      "Epoch 141/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 5.1795e-04 - accuracy: 1.0000 - val_loss: 0.0255 - val_accuracy: 0.9930\n",
      "Epoch 142/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 5.0978e-04 - accuracy: 1.0000 - val_loss: 0.0257 - val_accuracy: 0.9930\n",
      "Epoch 143/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 5.0166e-04 - accuracy: 1.0000 - val_loss: 0.0251 - val_accuracy: 0.9930\n",
      "Epoch 144/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 4.9356e-04 - accuracy: 1.0000 - val_loss: 0.0256 - val_accuracy: 0.9937\n",
      "Epoch 145/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 4.8583e-04 - accuracy: 1.0000 - val_loss: 0.0254 - val_accuracy: 0.9930\n",
      "Epoch 146/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 4.7787e-04 - accuracy: 1.0000 - val_loss: 0.0251 - val_accuracy: 0.9930\n",
      "Epoch 147/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 4.7011e-04 - accuracy: 1.0000 - val_loss: 0.0257 - val_accuracy: 0.9930\n",
      "Epoch 148/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 4.6215e-04 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 0.9930\n",
      "Epoch 149/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 4.5620e-04 - accuracy: 1.0000 - val_loss: 0.0252 - val_accuracy: 0.9937\n",
      "Epoch 150/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 4.4966e-04 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 0.9930\n",
      "Epoch 151/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 4.4201e-04 - accuracy: 1.0000 - val_loss: 0.0252 - val_accuracy: 0.9937\n",
      "Epoch 152/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 4.3592e-04 - accuracy: 1.0000 - val_loss: 0.0248 - val_accuracy: 0.9930\n",
      "Epoch 153/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 4.2914e-04 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9937\n",
      "Epoch 154/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 4.2299e-04 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 0.9930\n",
      "Epoch 155/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 4.1709e-04 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 0.9937\n",
      "Epoch 156/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 4.1061e-04 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 0.9930\n",
      "Epoch 157/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 4.0455e-04 - accuracy: 1.0000 - val_loss: 0.0250 - val_accuracy: 0.9930\n",
      "Epoch 158/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 3.9850e-04 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9930\n",
      "Epoch 159/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 3.9208e-04 - accuracy: 1.0000 - val_loss: 0.0247 - val_accuracy: 0.9930\n",
      "Epoch 160/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 3.8639e-04 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 0.9930\n",
      "Epoch 161/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 3.8078e-04 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 0.9922\n",
      "Epoch 162/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 3.7635e-04 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 0.9922\n",
      "Epoch 163/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 3.7099e-04 - accuracy: 1.0000 - val_loss: 0.0242 - val_accuracy: 0.9930\n",
      "Epoch 164/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 3.6527e-04 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 0.9922\n",
      "Epoch 165/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 3.6062e-04 - accuracy: 1.0000 - val_loss: 0.0242 - val_accuracy: 0.9930\n",
      "Epoch 166/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 3.5561e-04 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 0.9922\n",
      "Epoch 167/500\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 3.5121e-04 - accuracy: 1.0000 - val_loss: 0.0242 - val_accuracy: 0.9930\n",
      "Epoch 168/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 3.4610e-04 - accuracy: 1.0000 - val_loss: 0.0242 - val_accuracy: 0.9914\n",
      "Epoch 169/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 3.4162e-04 - accuracy: 1.0000 - val_loss: 0.0239 - val_accuracy: 0.9930\n",
      "Epoch 170/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 3.3691e-04 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 0.9922\n",
      "Epoch 171/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 3.3243e-04 - accuracy: 1.0000 - val_loss: 0.0242 - val_accuracy: 0.9922\n",
      "Epoch 172/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 3.2795e-04 - accuracy: 1.0000 - val_loss: 0.0245 - val_accuracy: 0.9922\n",
      "Epoch 173/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 3.2329e-04 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 0.9922\n",
      "Epoch 174/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 3.1938e-04 - accuracy: 1.0000 - val_loss: 0.0242 - val_accuracy: 0.9930\n",
      "Epoch 175/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 3.1578e-04 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 0.9922\n",
      "Epoch 176/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 3.1165e-04 - accuracy: 1.0000 - val_loss: 0.0241 - val_accuracy: 0.9914\n",
      "Epoch 177/500\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.0740e-04 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 0.9922\n",
      "Epoch 178/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 3.0338e-04 - accuracy: 1.0000 - val_loss: 0.0239 - val_accuracy: 0.9922\n",
      "Epoch 179/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 2.9937e-04 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 0.9922\n",
      "Epoch 180/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 2.9528e-04 - accuracy: 1.0000 - val_loss: 0.0237 - val_accuracy: 0.9922\n",
      "Epoch 181/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 2.9207e-04 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 0.9922\n",
      "Epoch 182/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 2.8766e-04 - accuracy: 1.0000 - val_loss: 0.0240 - val_accuracy: 0.9922\n",
      "Epoch 183/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 2.8430e-04 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 0.9914\n",
      "Epoch 184/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 2.8095e-04 - accuracy: 1.0000 - val_loss: 0.0235 - val_accuracy: 0.9914\n",
      "Epoch 185/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 2.7714e-04 - accuracy: 1.0000 - val_loss: 0.0236 - val_accuracy: 0.9914\n",
      "Epoch 186/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 2.7469e-04 - accuracy: 1.0000 - val_loss: 0.0240 - val_accuracy: 0.9914\n",
      "Epoch 187/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 2.7161e-04 - accuracy: 1.0000 - val_loss: 0.0235 - val_accuracy: 0.9914\n",
      "Epoch 188/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 2.6755e-04 - accuracy: 1.0000 - val_loss: 0.0241 - val_accuracy: 0.9914\n",
      "Epoch 189/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 2.6447e-04 - accuracy: 1.0000 - val_loss: 0.0237 - val_accuracy: 0.9914\n",
      "Epoch 190/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 2.6202e-04 - accuracy: 1.0000 - val_loss: 0.0236 - val_accuracy: 0.9914\n",
      "Epoch 191/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 2.5868e-04 - accuracy: 1.0000 - val_loss: 0.0234 - val_accuracy: 0.9914\n",
      "Epoch 192/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 2.5536e-04 - accuracy: 1.0000 - val_loss: 0.0234 - val_accuracy: 0.9914\n",
      "Epoch 193/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 2.5187e-04 - accuracy: 1.0000 - val_loss: 0.0233 - val_accuracy: 0.9914\n",
      "Epoch 194/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 2.4886e-04 - accuracy: 1.0000 - val_loss: 0.0236 - val_accuracy: 0.9914\n",
      "Epoch 195/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 2.4622e-04 - accuracy: 1.0000 - val_loss: 0.0234 - val_accuracy: 0.9914\n",
      "Epoch 196/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 2.4305e-04 - accuracy: 1.0000 - val_loss: 0.0234 - val_accuracy: 0.9914\n",
      "Epoch 197/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 2.4017e-04 - accuracy: 1.0000 - val_loss: 0.0235 - val_accuracy: 0.9914\n",
      "Epoch 198/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 2.3755e-04 - accuracy: 1.0000 - val_loss: 0.0231 - val_accuracy: 0.9914\n",
      "Epoch 199/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 2.3467e-04 - accuracy: 1.0000 - val_loss: 0.0230 - val_accuracy: 0.9914\n",
      "Epoch 200/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 2.3199e-04 - accuracy: 1.0000 - val_loss: 0.0233 - val_accuracy: 0.9914\n",
      "Epoch 201/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 2.2945e-04 - accuracy: 1.0000 - val_loss: 0.0233 - val_accuracy: 0.9914\n",
      "Epoch 202/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 2.2671e-04 - accuracy: 1.0000 - val_loss: 0.0234 - val_accuracy: 0.9914\n",
      "Epoch 203/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 2.2441e-04 - accuracy: 1.0000 - val_loss: 0.0231 - val_accuracy: 0.9914\n",
      "Epoch 204/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 2.2197e-04 - accuracy: 1.0000 - val_loss: 0.0232 - val_accuracy: 0.9914\n",
      "Epoch 205/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 2.1927e-04 - accuracy: 1.0000 - val_loss: 0.0236 - val_accuracy: 0.9914\n",
      "Epoch 206/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 2.1702e-04 - accuracy: 1.0000 - val_loss: 0.0230 - val_accuracy: 0.9914\n",
      "Epoch 207/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 2.1523e-04 - accuracy: 1.0000 - val_loss: 0.0237 - val_accuracy: 0.9914\n",
      "Epoch 208/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 2.1317e-04 - accuracy: 1.0000 - val_loss: 0.0232 - val_accuracy: 0.9914\n",
      "Epoch 209/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 2.1082e-04 - accuracy: 1.0000 - val_loss: 0.0234 - val_accuracy: 0.9914\n",
      "Epoch 210/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 2.0872e-04 - accuracy: 1.0000 - val_loss: 0.0229 - val_accuracy: 0.9914\n",
      "Epoch 211/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 2.0556e-04 - accuracy: 1.0000 - val_loss: 0.0227 - val_accuracy: 0.9914\n",
      "Epoch 212/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 2.0286e-04 - accuracy: 1.0000 - val_loss: 0.0235 - val_accuracy: 0.9914\n",
      "Epoch 213/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 2.0111e-04 - accuracy: 1.0000 - val_loss: 0.0228 - val_accuracy: 0.9914\n",
      "Epoch 214/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.9876e-04 - accuracy: 1.0000 - val_loss: 0.0233 - val_accuracy: 0.9922\n",
      "Epoch 215/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.9635e-04 - accuracy: 1.0000 - val_loss: 0.0231 - val_accuracy: 0.9914\n",
      "Epoch 216/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.9430e-04 - accuracy: 1.0000 - val_loss: 0.0230 - val_accuracy: 0.9914\n",
      "Epoch 217/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.9265e-04 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 0.9914\n",
      "Epoch 218/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.9042e-04 - accuracy: 1.0000 - val_loss: 0.0239 - val_accuracy: 0.9914\n",
      "Epoch 219/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.8890e-04 - accuracy: 1.0000 - val_loss: 0.0224 - val_accuracy: 0.9914\n",
      "Epoch 220/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.8665e-04 - accuracy: 1.0000 - val_loss: 0.0232 - val_accuracy: 0.9914\n",
      "Epoch 221/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.8443e-04 - accuracy: 1.0000 - val_loss: 0.0226 - val_accuracy: 0.9914\n",
      "Epoch 222/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.8242e-04 - accuracy: 1.0000 - val_loss: 0.0234 - val_accuracy: 0.9914\n",
      "Epoch 223/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.8053e-04 - accuracy: 1.0000 - val_loss: 0.0226 - val_accuracy: 0.9914\n",
      "Epoch 224/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.7855e-04 - accuracy: 1.0000 - val_loss: 0.0231 - val_accuracy: 0.9914\n",
      "Epoch 225/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.7674e-04 - accuracy: 1.0000 - val_loss: 0.0229 - val_accuracy: 0.9914\n",
      "Epoch 226/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.7504e-04 - accuracy: 1.0000 - val_loss: 0.0229 - val_accuracy: 0.9914\n",
      "Epoch 227/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.7329e-04 - accuracy: 1.0000 - val_loss: 0.0228 - val_accuracy: 0.9914\n",
      "Epoch 228/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.7180e-04 - accuracy: 1.0000 - val_loss: 0.0227 - val_accuracy: 0.9914\n",
      "Epoch 229/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.6985e-04 - accuracy: 1.0000 - val_loss: 0.0232 - val_accuracy: 0.9914\n",
      "Epoch 230/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.6819e-04 - accuracy: 1.0000 - val_loss: 0.0228 - val_accuracy: 0.9914\n",
      "Epoch 231/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.6648e-04 - accuracy: 1.0000 - val_loss: 0.0228 - val_accuracy: 0.9914\n",
      "Epoch 232/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 1.6470e-04 - accuracy: 1.0000 - val_loss: 0.0228 - val_accuracy: 0.9914\n",
      "Epoch 233/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.6313e-04 - accuracy: 1.0000 - val_loss: 0.0230 - val_accuracy: 0.9914\n",
      "Epoch 234/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.6179e-04 - accuracy: 1.0000 - val_loss: 0.0228 - val_accuracy: 0.9914\n",
      "Epoch 235/500\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 1.6022e-04 - accuracy: 1.0000 - val_loss: 0.0227 - val_accuracy: 0.9914\n",
      "Epoch 236/500\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.5824e-04 - accuracy: 1.0000 - val_loss: 0.0225 - val_accuracy: 0.9914\n",
      "Epoch 237/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 1.5694e-04 - accuracy: 1.0000 - val_loss: 0.0230 - val_accuracy: 0.9914\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "callback_es = EarlyStopping(monitor='val_loss', patience=20)\n",
    "history = model.fit(\n",
    "    [X_train_encoder, Y_train_decoder_input],\n",
    "    Y_train_decoder_output,\n",
    "    batch_size=64,\n",
    "    epochs=500,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[callback_es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b99dafc-adb3-4c2f-babb-8dfd72ce6017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(text):\n",
    "    encoder_input = tokenizer.texts_to_sequences([text]) \n",
    "    encoder_input = pad_sequences(encoder_input, maxlen=8, padding='post', truncating='post', dtype='float32')\n",
    "    encoder_input = to_categorical(encoder_input, num_classes=len(tokenizer.word_index)+1)\n",
    "    \n",
    "    T_y = 8\n",
    "    n_y = len(tokenizer.word_index)+1\n",
    "    decoder_input = np.zeros([1, T_y, n_y])\n",
    "    word = '<start>'\n",
    "    idx = tokenizer.word_index[word]\n",
    "    \n",
    "    translated_text = ''\n",
    "    for t in range(T_y):\n",
    "        translated_text += word + ' '\n",
    "        decoder_input[0, t, idx] = 1\n",
    "        y_hat = model.predict([encoder_input, decoder_input])\n",
    "        idx = np.argmax(y_hat[0, t, :])\n",
    "        word = tokenizer.index_word[idx]\n",
    "        if word == '<end>':\n",
    "            translated_text += word + ' '\n",
    "            break\n",
    "\n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "302dec07-8129-4963-8962-1b16b2c201b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "----------------\n",
      "French text: <start> neuf cent quatre-vingt-dix-neuf <end>\n",
      "Translation: <start> nine hundred and ninety nine <end> \n",
      "Ground truth: <start> nine hundred and ninety-nine <end>\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "----------------\n",
      "French text: <start> vingt-six <end>\n",
      "Translation: <start> twenty six <end> \n",
      "Ground truth: <start> twenty-six <end>\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "----------------\n",
      "French text: <start> cinquante-six <end>\n",
      "Translation: <start> fifty six <end> \n",
      "Ground truth: <start> fifty-six <end>\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "----------------\n",
      "French text: <start> cent huit <end>\n",
      "Translation: <start> one hundred and eight <end> \n",
      "Ground truth: <start> one hundred and eight <end>\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "----------------\n",
      "French text: <start> trois cent soixante et onze <end>\n",
      "Translation: <start> three hundred and seventy one <end> \n",
      "Ground truth: <start> three hundred and seventy-one <end>\n"
     ]
    }
   ],
   "source": [
    "def generate_example_translations():\n",
    "    indices = np.random.choice(200, 5, replace=False)\n",
    "    for i in range(5):    \n",
    "        text = test_source[indices[i]]\n",
    "        translated_text = translate(text)\n",
    "        print (\"----------------\")\n",
    "        print (\"French text:\", test_source[indices[i]])\n",
    "        print (\"Translation:\", translated_text)\n",
    "        print (\"Ground truth:\", test_target[indices[i]])\n",
    "\n",
    "    return None\n",
    "\n",
    "generate_example_translations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4822fd4b-71f3-48f8-8261-a27dfc15628e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
