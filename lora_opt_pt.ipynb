{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c814f038-f4e7-49c6-b6e4-1266c34b8e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OPTForCausalLM(\n",
       "  (model): OPTModel(\n",
       "    (decoder): OPTDecoder(\n",
       "      (embed_tokens): Embedding(50272, 768, padding_idx=1)\n",
       "      (embed_positions): OPTLearnedPositionalEmbedding(2050, 768)\n",
       "      (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x OPTDecoderLayer(\n",
       "          (self_attn): OPTSdpaAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50272, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoConfig, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "model_name = \"facebook/opt-125m\"\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    config=config,\n",
    ").to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4257766-bd5e-4a2f-bf71-adb612b734c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OPTForSequenceClassification were not initialized from the model checkpoint at facebook/opt-125m and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OPTForSequenceClassification(\n",
       "  (model): OPTModel(\n",
       "    (decoder): OPTDecoder(\n",
       "      (embed_tokens): Embedding(50272, 768, padding_idx=1)\n",
       "      (embed_positions): OPTLearnedPositionalEmbedding(2050, 768)\n",
       "      (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x OPTDecoderLayer(\n",
       "          (self_attn): OPTSdpaAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (score): Linear(in_features=768, out_features=2, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    config=config,\n",
    ").to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da7eaf7b-6cad-4f1f-9c80-c1724f65737a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===========================================================================\n",
       "Layer (type:depth-idx)                             Param #\n",
       "===========================================================================\n",
       "OPTForSequenceClassification                       --\n",
       "├─OPTModel: 1-1                                    --\n",
       "│    └─OPTDecoder: 2-1                             --\n",
       "│    │    └─Embedding: 3-1                         38,608,896\n",
       "│    │    └─OPTLearnedPositionalEmbedding: 3-2     1,574,400\n",
       "│    │    └─LayerNorm: 3-3                         1,536\n",
       "│    │    └─ModuleList: 3-4                        85,054,464\n",
       "├─Linear: 1-2                                      1,536\n",
       "===========================================================================\n",
       "Total params: 125,240,832\n",
       "Trainable params: 125,240,832\n",
       "Non-trainable params: 0\n",
       "==========================================================================="
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eca561b8-62f7-423e-a16d-4fd60e33dd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from torch import nn\n",
    "\n",
    "class LoRALayer(nn.Module):\n",
    "    def __init__(self, weight, bias, lora_dim):\n",
    "        super(LoRALayer, self).__init__()\n",
    "\n",
    "        row, column = weight.shape\n",
    "\n",
    "        # restore Linear\n",
    "        if bias is None:\n",
    "            self.linear = nn.Linear(column, row, bias=False)\n",
    "            self.linear.load_state_dict({\"weight\": weight})\n",
    "        else:\n",
    "            self.linear = nn.Linear(column, row)\n",
    "            self.linear.load_state_dict({\"weight\": weight, \"bias\": bias})\n",
    "\n",
    "        # create LoRA weights (with initialization)\n",
    "        self.lora_right = nn.Parameter(torch.zeros(column, lora_dim))\n",
    "        nn.init.kaiming_uniform_(self.lora_right, a=math.sqrt(5))\n",
    "        self.lora_left = nn.Parameter(torch.zeros(lora_dim, row))\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.linear(input)\n",
    "        y = input @ self.lora_right @ self.lora_left\n",
    "        return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "73deff1c-ce45-41da-9301-1476659c1aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_dim = 16\n",
    "\n",
    "# get target module name\n",
    "target_names = []\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, nn.Linear) and \"decoder.layers.\" in name:\n",
    "        target_names.append(name)\n",
    "\n",
    "# replace each module with LoRA\n",
    "for name in target_names:\n",
    "    name_struct = name.split(\".\")\n",
    "    # get target module\n",
    "    module_list = [model]\n",
    "    for struct in name_struct:\n",
    "        module_list.append(getattr(module_list[-1], struct))\n",
    "    # build LoRA\n",
    "    lora = LoRALayer(\n",
    "        weight = module_list[-1].weight,\n",
    "        bias = module_list[-1].bias,\n",
    "        lora_dim = lora_dim,\n",
    "    ).to(device)\n",
    "    # replace\n",
    "    module_list[-2].__setattr__(name_struct[-1], lora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f253ddf4-ebdc-476c-a609-479af5795a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OPTForSequenceClassification(\n",
       "  (model): OPTModel(\n",
       "    (decoder): OPTDecoder(\n",
       "      (embed_tokens): Embedding(50272, 768, padding_idx=1)\n",
       "      (embed_positions): OPTLearnedPositionalEmbedding(2050, 768)\n",
       "      (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x OPTDecoderLayer(\n",
       "          (self_attn): OPTSdpaAttention(\n",
       "            (k_proj): LoRALayer(\n",
       "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (v_proj): LoRALayer(\n",
       "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (q_proj): LoRALayer(\n",
       "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (out_proj): LoRALayer(\n",
       "              (linear): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): LoRALayer(\n",
       "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (fc2): LoRALayer(\n",
       "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (score): Linear(in_features=768, out_features=2, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "01782836-efb5-43d6-91ba-271d68ff4912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.decoder.embed_tokens.weight\n",
      "model.decoder.embed_positions.weight\n",
      "model.decoder.final_layer_norm.weight\n",
      "model.decoder.final_layer_norm.bias\n",
      "model.decoder.layers.0.self_attn.k_proj.lora_right\n",
      "model.decoder.layers.0.self_attn.k_proj.lora_left\n",
      "model.decoder.layers.0.self_attn.k_proj.linear.weight\n",
      "model.decoder.layers.0.self_attn.k_proj.linear.bias\n",
      "model.decoder.layers.0.self_attn.v_proj.lora_right\n",
      "model.decoder.layers.0.self_attn.v_proj.lora_left\n",
      "model.decoder.layers.0.self_attn.v_proj.linear.weight\n",
      "model.decoder.layers.0.self_attn.v_proj.linear.bias\n",
      "model.decoder.layers.0.self_attn.q_proj.lora_right\n",
      "model.decoder.layers.0.self_attn.q_proj.lora_left\n",
      "model.decoder.layers.0.self_attn.q_proj.linear.weight\n",
      "model.decoder.layers.0.self_attn.q_proj.linear.bias\n",
      "model.decoder.layers.0.self_attn.out_proj.lora_right\n",
      "model.decoder.layers.0.self_attn.out_proj.lora_left\n",
      "model.decoder.layers.0.self_attn.out_proj.linear.weight\n",
      "model.decoder.layers.0.self_attn.out_proj.linear.bias\n",
      "model.decoder.layers.0.self_attn_layer_norm.weight\n",
      "model.decoder.layers.0.self_attn_layer_norm.bias\n",
      "model.decoder.layers.0.fc1.lora_right\n",
      "model.decoder.layers.0.fc1.lora_left\n",
      "model.decoder.layers.0.fc1.linear.weight\n",
      "model.decoder.layers.0.fc1.linear.bias\n",
      "model.decoder.layers.0.fc2.lora_right\n",
      "model.decoder.layers.0.fc2.lora_left\n",
      "model.decoder.layers.0.fc2.linear.weight\n",
      "model.decoder.layers.0.fc2.linear.bias\n",
      "model.decoder.layers.0.final_layer_norm.weight\n",
      "model.decoder.layers.0.final_layer_norm.bias\n",
      "model.decoder.layers.1.self_attn.k_proj.lora_right\n",
      "model.decoder.layers.1.self_attn.k_proj.lora_left\n",
      "model.decoder.layers.1.self_attn.k_proj.linear.weight\n",
      "model.decoder.layers.1.self_attn.k_proj.linear.bias\n",
      "model.decoder.layers.1.self_attn.v_proj.lora_right\n",
      "model.decoder.layers.1.self_attn.v_proj.lora_left\n",
      "model.decoder.layers.1.self_attn.v_proj.linear.weight\n",
      "model.decoder.layers.1.self_attn.v_proj.linear.bias\n",
      "model.decoder.layers.1.self_attn.q_proj.lora_right\n",
      "model.decoder.layers.1.self_attn.q_proj.lora_left\n",
      "model.decoder.layers.1.self_attn.q_proj.linear.weight\n",
      "model.decoder.layers.1.self_attn.q_proj.linear.bias\n",
      "model.decoder.layers.1.self_attn.out_proj.lora_right\n",
      "model.decoder.layers.1.self_attn.out_proj.lora_left\n",
      "model.decoder.layers.1.self_attn.out_proj.linear.weight\n",
      "model.decoder.layers.1.self_attn.out_proj.linear.bias\n",
      "model.decoder.layers.1.self_attn_layer_norm.weight\n",
      "model.decoder.layers.1.self_attn_layer_norm.bias\n",
      "model.decoder.layers.1.fc1.lora_right\n",
      "model.decoder.layers.1.fc1.lora_left\n",
      "model.decoder.layers.1.fc1.linear.weight\n",
      "model.decoder.layers.1.fc1.linear.bias\n",
      "model.decoder.layers.1.fc2.lora_right\n",
      "model.decoder.layers.1.fc2.lora_left\n",
      "model.decoder.layers.1.fc2.linear.weight\n",
      "model.decoder.layers.1.fc2.linear.bias\n",
      "model.decoder.layers.1.final_layer_norm.weight\n",
      "model.decoder.layers.1.final_layer_norm.bias\n",
      "model.decoder.layers.2.self_attn.k_proj.lora_right\n",
      "model.decoder.layers.2.self_attn.k_proj.lora_left\n",
      "model.decoder.layers.2.self_attn.k_proj.linear.weight\n",
      "model.decoder.layers.2.self_attn.k_proj.linear.bias\n",
      "model.decoder.layers.2.self_attn.v_proj.lora_right\n",
      "model.decoder.layers.2.self_attn.v_proj.lora_left\n",
      "model.decoder.layers.2.self_attn.v_proj.linear.weight\n",
      "model.decoder.layers.2.self_attn.v_proj.linear.bias\n",
      "model.decoder.layers.2.self_attn.q_proj.lora_right\n",
      "model.decoder.layers.2.self_attn.q_proj.lora_left\n",
      "model.decoder.layers.2.self_attn.q_proj.linear.weight\n",
      "model.decoder.layers.2.self_attn.q_proj.linear.bias\n",
      "model.decoder.layers.2.self_attn.out_proj.lora_right\n",
      "model.decoder.layers.2.self_attn.out_proj.lora_left\n",
      "model.decoder.layers.2.self_attn.out_proj.linear.weight\n",
      "model.decoder.layers.2.self_attn.out_proj.linear.bias\n",
      "model.decoder.layers.2.self_attn_layer_norm.weight\n",
      "model.decoder.layers.2.self_attn_layer_norm.bias\n",
      "model.decoder.layers.2.fc1.lora_right\n",
      "model.decoder.layers.2.fc1.lora_left\n",
      "model.decoder.layers.2.fc1.linear.weight\n",
      "model.decoder.layers.2.fc1.linear.bias\n",
      "model.decoder.layers.2.fc2.lora_right\n",
      "model.decoder.layers.2.fc2.lora_left\n",
      "model.decoder.layers.2.fc2.linear.weight\n",
      "model.decoder.layers.2.fc2.linear.bias\n",
      "model.decoder.layers.2.final_layer_norm.weight\n",
      "model.decoder.layers.2.final_layer_norm.bias\n",
      "model.decoder.layers.3.self_attn.k_proj.lora_right\n",
      "model.decoder.layers.3.self_attn.k_proj.lora_left\n",
      "model.decoder.layers.3.self_attn.k_proj.linear.weight\n",
      "model.decoder.layers.3.self_attn.k_proj.linear.bias\n",
      "model.decoder.layers.3.self_attn.v_proj.lora_right\n",
      "model.decoder.layers.3.self_attn.v_proj.lora_left\n",
      "model.decoder.layers.3.self_attn.v_proj.linear.weight\n",
      "model.decoder.layers.3.self_attn.v_proj.linear.bias\n",
      "model.decoder.layers.3.self_attn.q_proj.lora_right\n",
      "model.decoder.layers.3.self_attn.q_proj.lora_left\n",
      "model.decoder.layers.3.self_attn.q_proj.linear.weight\n",
      "model.decoder.layers.3.self_attn.q_proj.linear.bias\n",
      "model.decoder.layers.3.self_attn.out_proj.lora_right\n",
      "model.decoder.layers.3.self_attn.out_proj.lora_left\n",
      "model.decoder.layers.3.self_attn.out_proj.linear.weight\n",
      "model.decoder.layers.3.self_attn.out_proj.linear.bias\n",
      "model.decoder.layers.3.self_attn_layer_norm.weight\n",
      "model.decoder.layers.3.self_attn_layer_norm.bias\n",
      "model.decoder.layers.3.fc1.lora_right\n",
      "model.decoder.layers.3.fc1.lora_left\n",
      "model.decoder.layers.3.fc1.linear.weight\n",
      "model.decoder.layers.3.fc1.linear.bias\n",
      "model.decoder.layers.3.fc2.lora_right\n",
      "model.decoder.layers.3.fc2.lora_left\n",
      "model.decoder.layers.3.fc2.linear.weight\n",
      "model.decoder.layers.3.fc2.linear.bias\n",
      "model.decoder.layers.3.final_layer_norm.weight\n",
      "model.decoder.layers.3.final_layer_norm.bias\n",
      "model.decoder.layers.4.self_attn.k_proj.lora_right\n",
      "model.decoder.layers.4.self_attn.k_proj.lora_left\n",
      "model.decoder.layers.4.self_attn.k_proj.linear.weight\n",
      "model.decoder.layers.4.self_attn.k_proj.linear.bias\n",
      "model.decoder.layers.4.self_attn.v_proj.lora_right\n",
      "model.decoder.layers.4.self_attn.v_proj.lora_left\n",
      "model.decoder.layers.4.self_attn.v_proj.linear.weight\n",
      "model.decoder.layers.4.self_attn.v_proj.linear.bias\n",
      "model.decoder.layers.4.self_attn.q_proj.lora_right\n",
      "model.decoder.layers.4.self_attn.q_proj.lora_left\n",
      "model.decoder.layers.4.self_attn.q_proj.linear.weight\n",
      "model.decoder.layers.4.self_attn.q_proj.linear.bias\n",
      "model.decoder.layers.4.self_attn.out_proj.lora_right\n",
      "model.decoder.layers.4.self_attn.out_proj.lora_left\n",
      "model.decoder.layers.4.self_attn.out_proj.linear.weight\n",
      "model.decoder.layers.4.self_attn.out_proj.linear.bias\n",
      "model.decoder.layers.4.self_attn_layer_norm.weight\n",
      "model.decoder.layers.4.self_attn_layer_norm.bias\n",
      "model.decoder.layers.4.fc1.lora_right\n",
      "model.decoder.layers.4.fc1.lora_left\n",
      "model.decoder.layers.4.fc1.linear.weight\n",
      "model.decoder.layers.4.fc1.linear.bias\n",
      "model.decoder.layers.4.fc2.lora_right\n",
      "model.decoder.layers.4.fc2.lora_left\n",
      "model.decoder.layers.4.fc2.linear.weight\n",
      "model.decoder.layers.4.fc2.linear.bias\n",
      "model.decoder.layers.4.final_layer_norm.weight\n",
      "model.decoder.layers.4.final_layer_norm.bias\n",
      "model.decoder.layers.5.self_attn.k_proj.lora_right\n",
      "model.decoder.layers.5.self_attn.k_proj.lora_left\n",
      "model.decoder.layers.5.self_attn.k_proj.linear.weight\n",
      "model.decoder.layers.5.self_attn.k_proj.linear.bias\n",
      "model.decoder.layers.5.self_attn.v_proj.lora_right\n",
      "model.decoder.layers.5.self_attn.v_proj.lora_left\n",
      "model.decoder.layers.5.self_attn.v_proj.linear.weight\n",
      "model.decoder.layers.5.self_attn.v_proj.linear.bias\n",
      "model.decoder.layers.5.self_attn.q_proj.lora_right\n",
      "model.decoder.layers.5.self_attn.q_proj.lora_left\n",
      "model.decoder.layers.5.self_attn.q_proj.linear.weight\n",
      "model.decoder.layers.5.self_attn.q_proj.linear.bias\n",
      "model.decoder.layers.5.self_attn.out_proj.lora_right\n",
      "model.decoder.layers.5.self_attn.out_proj.lora_left\n",
      "model.decoder.layers.5.self_attn.out_proj.linear.weight\n",
      "model.decoder.layers.5.self_attn.out_proj.linear.bias\n",
      "model.decoder.layers.5.self_attn_layer_norm.weight\n",
      "model.decoder.layers.5.self_attn_layer_norm.bias\n",
      "model.decoder.layers.5.fc1.lora_right\n",
      "model.decoder.layers.5.fc1.lora_left\n",
      "model.decoder.layers.5.fc1.linear.weight\n",
      "model.decoder.layers.5.fc1.linear.bias\n",
      "model.decoder.layers.5.fc2.lora_right\n",
      "model.decoder.layers.5.fc2.lora_left\n",
      "model.decoder.layers.5.fc2.linear.weight\n",
      "model.decoder.layers.5.fc2.linear.bias\n",
      "model.decoder.layers.5.final_layer_norm.weight\n",
      "model.decoder.layers.5.final_layer_norm.bias\n",
      "model.decoder.layers.6.self_attn.k_proj.lora_right\n",
      "model.decoder.layers.6.self_attn.k_proj.lora_left\n",
      "model.decoder.layers.6.self_attn.k_proj.linear.weight\n",
      "model.decoder.layers.6.self_attn.k_proj.linear.bias\n",
      "model.decoder.layers.6.self_attn.v_proj.lora_right\n",
      "model.decoder.layers.6.self_attn.v_proj.lora_left\n",
      "model.decoder.layers.6.self_attn.v_proj.linear.weight\n",
      "model.decoder.layers.6.self_attn.v_proj.linear.bias\n",
      "model.decoder.layers.6.self_attn.q_proj.lora_right\n",
      "model.decoder.layers.6.self_attn.q_proj.lora_left\n",
      "model.decoder.layers.6.self_attn.q_proj.linear.weight\n",
      "model.decoder.layers.6.self_attn.q_proj.linear.bias\n",
      "model.decoder.layers.6.self_attn.out_proj.lora_right\n",
      "model.decoder.layers.6.self_attn.out_proj.lora_left\n",
      "model.decoder.layers.6.self_attn.out_proj.linear.weight\n",
      "model.decoder.layers.6.self_attn.out_proj.linear.bias\n",
      "model.decoder.layers.6.self_attn_layer_norm.weight\n",
      "model.decoder.layers.6.self_attn_layer_norm.bias\n",
      "model.decoder.layers.6.fc1.lora_right\n",
      "model.decoder.layers.6.fc1.lora_left\n",
      "model.decoder.layers.6.fc1.linear.weight\n",
      "model.decoder.layers.6.fc1.linear.bias\n",
      "model.decoder.layers.6.fc2.lora_right\n",
      "model.decoder.layers.6.fc2.lora_left\n",
      "model.decoder.layers.6.fc2.linear.weight\n",
      "model.decoder.layers.6.fc2.linear.bias\n",
      "model.decoder.layers.6.final_layer_norm.weight\n",
      "model.decoder.layers.6.final_layer_norm.bias\n",
      "model.decoder.layers.7.self_attn.k_proj.lora_right\n",
      "model.decoder.layers.7.self_attn.k_proj.lora_left\n",
      "model.decoder.layers.7.self_attn.k_proj.linear.weight\n",
      "model.decoder.layers.7.self_attn.k_proj.linear.bias\n",
      "model.decoder.layers.7.self_attn.v_proj.lora_right\n",
      "model.decoder.layers.7.self_attn.v_proj.lora_left\n",
      "model.decoder.layers.7.self_attn.v_proj.linear.weight\n",
      "model.decoder.layers.7.self_attn.v_proj.linear.bias\n",
      "model.decoder.layers.7.self_attn.q_proj.lora_right\n",
      "model.decoder.layers.7.self_attn.q_proj.lora_left\n",
      "model.decoder.layers.7.self_attn.q_proj.linear.weight\n",
      "model.decoder.layers.7.self_attn.q_proj.linear.bias\n",
      "model.decoder.layers.7.self_attn.out_proj.lora_right\n",
      "model.decoder.layers.7.self_attn.out_proj.lora_left\n",
      "model.decoder.layers.7.self_attn.out_proj.linear.weight\n",
      "model.decoder.layers.7.self_attn.out_proj.linear.bias\n",
      "model.decoder.layers.7.self_attn_layer_norm.weight\n",
      "model.decoder.layers.7.self_attn_layer_norm.bias\n",
      "model.decoder.layers.7.fc1.lora_right\n",
      "model.decoder.layers.7.fc1.lora_left\n",
      "model.decoder.layers.7.fc1.linear.weight\n",
      "model.decoder.layers.7.fc1.linear.bias\n",
      "model.decoder.layers.7.fc2.lora_right\n",
      "model.decoder.layers.7.fc2.lora_left\n",
      "model.decoder.layers.7.fc2.linear.weight\n",
      "model.decoder.layers.7.fc2.linear.bias\n",
      "model.decoder.layers.7.final_layer_norm.weight\n",
      "model.decoder.layers.7.final_layer_norm.bias\n",
      "model.decoder.layers.8.self_attn.k_proj.lora_right\n",
      "model.decoder.layers.8.self_attn.k_proj.lora_left\n",
      "model.decoder.layers.8.self_attn.k_proj.linear.weight\n",
      "model.decoder.layers.8.self_attn.k_proj.linear.bias\n",
      "model.decoder.layers.8.self_attn.v_proj.lora_right\n",
      "model.decoder.layers.8.self_attn.v_proj.lora_left\n",
      "model.decoder.layers.8.self_attn.v_proj.linear.weight\n",
      "model.decoder.layers.8.self_attn.v_proj.linear.bias\n",
      "model.decoder.layers.8.self_attn.q_proj.lora_right\n",
      "model.decoder.layers.8.self_attn.q_proj.lora_left\n",
      "model.decoder.layers.8.self_attn.q_proj.linear.weight\n",
      "model.decoder.layers.8.self_attn.q_proj.linear.bias\n",
      "model.decoder.layers.8.self_attn.out_proj.lora_right\n",
      "model.decoder.layers.8.self_attn.out_proj.lora_left\n",
      "model.decoder.layers.8.self_attn.out_proj.linear.weight\n",
      "model.decoder.layers.8.self_attn.out_proj.linear.bias\n",
      "model.decoder.layers.8.self_attn_layer_norm.weight\n",
      "model.decoder.layers.8.self_attn_layer_norm.bias\n",
      "model.decoder.layers.8.fc1.lora_right\n",
      "model.decoder.layers.8.fc1.lora_left\n",
      "model.decoder.layers.8.fc1.linear.weight\n",
      "model.decoder.layers.8.fc1.linear.bias\n",
      "model.decoder.layers.8.fc2.lora_right\n",
      "model.decoder.layers.8.fc2.lora_left\n",
      "model.decoder.layers.8.fc2.linear.weight\n",
      "model.decoder.layers.8.fc2.linear.bias\n",
      "model.decoder.layers.8.final_layer_norm.weight\n",
      "model.decoder.layers.8.final_layer_norm.bias\n",
      "model.decoder.layers.9.self_attn.k_proj.lora_right\n",
      "model.decoder.layers.9.self_attn.k_proj.lora_left\n",
      "model.decoder.layers.9.self_attn.k_proj.linear.weight\n",
      "model.decoder.layers.9.self_attn.k_proj.linear.bias\n",
      "model.decoder.layers.9.self_attn.v_proj.lora_right\n",
      "model.decoder.layers.9.self_attn.v_proj.lora_left\n",
      "model.decoder.layers.9.self_attn.v_proj.linear.weight\n",
      "model.decoder.layers.9.self_attn.v_proj.linear.bias\n",
      "model.decoder.layers.9.self_attn.q_proj.lora_right\n",
      "model.decoder.layers.9.self_attn.q_proj.lora_left\n",
      "model.decoder.layers.9.self_attn.q_proj.linear.weight\n",
      "model.decoder.layers.9.self_attn.q_proj.linear.bias\n",
      "model.decoder.layers.9.self_attn.out_proj.lora_right\n",
      "model.decoder.layers.9.self_attn.out_proj.lora_left\n",
      "model.decoder.layers.9.self_attn.out_proj.linear.weight\n",
      "model.decoder.layers.9.self_attn.out_proj.linear.bias\n",
      "model.decoder.layers.9.self_attn_layer_norm.weight\n",
      "model.decoder.layers.9.self_attn_layer_norm.bias\n",
      "model.decoder.layers.9.fc1.lora_right\n",
      "model.decoder.layers.9.fc1.lora_left\n",
      "model.decoder.layers.9.fc1.linear.weight\n",
      "model.decoder.layers.9.fc1.linear.bias\n",
      "model.decoder.layers.9.fc2.lora_right\n",
      "model.decoder.layers.9.fc2.lora_left\n",
      "model.decoder.layers.9.fc2.linear.weight\n",
      "model.decoder.layers.9.fc2.linear.bias\n",
      "model.decoder.layers.9.final_layer_norm.weight\n",
      "model.decoder.layers.9.final_layer_norm.bias\n",
      "model.decoder.layers.10.self_attn.k_proj.lora_right\n",
      "model.decoder.layers.10.self_attn.k_proj.lora_left\n",
      "model.decoder.layers.10.self_attn.k_proj.linear.weight\n",
      "model.decoder.layers.10.self_attn.k_proj.linear.bias\n",
      "model.decoder.layers.10.self_attn.v_proj.lora_right\n",
      "model.decoder.layers.10.self_attn.v_proj.lora_left\n",
      "model.decoder.layers.10.self_attn.v_proj.linear.weight\n",
      "model.decoder.layers.10.self_attn.v_proj.linear.bias\n",
      "model.decoder.layers.10.self_attn.q_proj.lora_right\n",
      "model.decoder.layers.10.self_attn.q_proj.lora_left\n",
      "model.decoder.layers.10.self_attn.q_proj.linear.weight\n",
      "model.decoder.layers.10.self_attn.q_proj.linear.bias\n",
      "model.decoder.layers.10.self_attn.out_proj.lora_right\n",
      "model.decoder.layers.10.self_attn.out_proj.lora_left\n",
      "model.decoder.layers.10.self_attn.out_proj.linear.weight\n",
      "model.decoder.layers.10.self_attn.out_proj.linear.bias\n",
      "model.decoder.layers.10.self_attn_layer_norm.weight\n",
      "model.decoder.layers.10.self_attn_layer_norm.bias\n",
      "model.decoder.layers.10.fc1.lora_right\n",
      "model.decoder.layers.10.fc1.lora_left\n",
      "model.decoder.layers.10.fc1.linear.weight\n",
      "model.decoder.layers.10.fc1.linear.bias\n",
      "model.decoder.layers.10.fc2.lora_right\n",
      "model.decoder.layers.10.fc2.lora_left\n",
      "model.decoder.layers.10.fc2.linear.weight\n",
      "model.decoder.layers.10.fc2.linear.bias\n",
      "model.decoder.layers.10.final_layer_norm.weight\n",
      "model.decoder.layers.10.final_layer_norm.bias\n",
      "model.decoder.layers.11.self_attn.k_proj.lora_right\n",
      "model.decoder.layers.11.self_attn.k_proj.lora_left\n",
      "model.decoder.layers.11.self_attn.k_proj.linear.weight\n",
      "model.decoder.layers.11.self_attn.k_proj.linear.bias\n",
      "model.decoder.layers.11.self_attn.v_proj.lora_right\n",
      "model.decoder.layers.11.self_attn.v_proj.lora_left\n",
      "model.decoder.layers.11.self_attn.v_proj.linear.weight\n",
      "model.decoder.layers.11.self_attn.v_proj.linear.bias\n",
      "model.decoder.layers.11.self_attn.q_proj.lora_right\n",
      "model.decoder.layers.11.self_attn.q_proj.lora_left\n",
      "model.decoder.layers.11.self_attn.q_proj.linear.weight\n",
      "model.decoder.layers.11.self_attn.q_proj.linear.bias\n",
      "model.decoder.layers.11.self_attn.out_proj.lora_right\n",
      "model.decoder.layers.11.self_attn.out_proj.lora_left\n",
      "model.decoder.layers.11.self_attn.out_proj.linear.weight\n",
      "model.decoder.layers.11.self_attn.out_proj.linear.bias\n",
      "model.decoder.layers.11.self_attn_layer_norm.weight\n",
      "model.decoder.layers.11.self_attn_layer_norm.bias\n",
      "model.decoder.layers.11.fc1.lora_right\n",
      "model.decoder.layers.11.fc1.lora_left\n",
      "model.decoder.layers.11.fc1.linear.weight\n",
      "model.decoder.layers.11.fc1.linear.bias\n",
      "model.decoder.layers.11.fc2.lora_right\n",
      "model.decoder.layers.11.fc2.lora_left\n",
      "model.decoder.layers.11.fc2.linear.weight\n",
      "model.decoder.layers.11.fc2.linear.bias\n",
      "model.decoder.layers.11.final_layer_norm.weight\n",
      "model.decoder.layers.11.final_layer_norm.bias\n",
      "score.weight\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print (name)\n",
    "    if \"lora_right\" in name or \"lora_left\" in name:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "db19245d-2a41-44d2-aad4-94efe5ad2946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===========================================================================\n",
       "Layer (type:depth-idx)                             Param #\n",
       "===========================================================================\n",
       "OPTForSequenceClassification                       --\n",
       "├─OPTModel: 1-1                                    --\n",
       "│    └─OPTDecoder: 2-1                             --\n",
       "│    │    └─Embedding: 3-1                         (38,608,896)\n",
       "│    │    └─OPTLearnedPositionalEmbedding: 3-2     (1,574,400)\n",
       "│    │    └─LayerNorm: 3-3                         (1,536)\n",
       "│    │    └─ModuleList: 3-4                        87,708,672\n",
       "├─Linear: 1-2                                      (1,536)\n",
       "===========================================================================\n",
       "Total params: 127,895,040\n",
       "Trainable params: 2,654,208\n",
       "Non-trainable params: 125,240,832\n",
       "==========================================================================="
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "260422c0-70a7-4db0-8945-29f9c84fef4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['labels', 'input_ids', 'token_type_ids', 'attention_mask']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import RobertaTokenizer\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], return_token_type_ids=True, truncation=True)\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\", truncation=True, do_lower_case=True)\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([\"sentence1\", \"sentence2\", \"idx\"])\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "tokenized_datasets[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1aa3073c-4f5c-4ed2-a18d-eb8114d7705b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"train\"], shuffle=True, batch_size=8, collate_fn=data_collator\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"validation\"], batch_size=8, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "62940f4a-c39e-4847-905e-56a5c9f0bc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 91/459 | Training loss: 0.7976 | accuracy: 0.5000\n",
      "Batch: 182/459 | Training loss: 0.6356 | accuracy: 0.6250\n",
      "Batch: 273/459 | Training loss: 0.5163 | accuracy: 0.8750\n",
      "Batch: 364/459 | Training loss: 0.6889 | accuracy: 0.5000\n",
      "Batch: 455/459 | Training loss: 0.2945 | accuracy: 1.0000\n",
      "Epoch: 1 | Train Loss: 0.6186 | Train Acc: 0.6778\n",
      "Epoch time elapsed: 00:00:54.88\n",
      "\n",
      "Batch: 91/459 | Training loss: 0.4864 | accuracy: 0.7500\n",
      "Batch: 182/459 | Training loss: 0.7397 | accuracy: 0.5000\n",
      "Batch: 273/459 | Training loss: 0.1362 | accuracy: 1.0000\n",
      "Batch: 364/459 | Training loss: 0.6364 | accuracy: 0.6250\n",
      "Batch: 455/459 | Training loss: 0.3255 | accuracy: 0.8750\n",
      "Epoch: 2 | Train Loss: 0.5305 | Train Acc: 0.7350\n",
      "Epoch time elapsed: 00:00:42.69\n",
      "\n",
      "Batch: 91/459 | Training loss: 0.7279 | accuracy: 0.7500\n",
      "Batch: 182/459 | Training loss: 0.2728 | accuracy: 1.0000\n",
      "Batch: 273/459 | Training loss: 0.5541 | accuracy: 0.6250\n",
      "Batch: 364/459 | Training loss: 0.7721 | accuracy: 0.6250\n",
      "Batch: 455/459 | Training loss: 1.0353 | accuracy: 0.5000\n",
      "Epoch: 3 | Train Loss: 0.4593 | Train Acc: 0.7947\n",
      "Epoch time elapsed: 00:00:42.60\n",
      "\n",
      "Batch: 91/459 | Training loss: 0.3672 | accuracy: 0.8750\n",
      "Batch: 182/459 | Training loss: 0.3729 | accuracy: 0.7500\n",
      "Batch: 273/459 | Training loss: 0.7119 | accuracy: 0.7500\n",
      "Batch: 364/459 | Training loss: 0.2737 | accuracy: 0.8750\n",
      "Batch: 455/459 | Training loss: 0.1119 | accuracy: 1.0000\n",
      "Epoch: 4 | Train Loss: 0.3959 | Train Acc: 0.8252\n",
      "Epoch time elapsed: 00:00:42.97\n",
      "\n",
      "Batch: 91/459 | Training loss: 0.4035 | accuracy: 0.8750\n",
      "Batch: 182/459 | Training loss: 0.2812 | accuracy: 0.8750\n",
      "Batch: 273/459 | Training loss: 0.5591 | accuracy: 0.7500\n",
      "Batch: 364/459 | Training loss: 0.3693 | accuracy: 0.7500\n",
      "Batch: 455/459 | Training loss: 0.6412 | accuracy: 0.6250\n",
      "Epoch: 5 | Train Loss: 0.3379 | Train Acc: 0.8581\n",
      "Epoch time elapsed: 00:00:42.50\n",
      "\n",
      "Batch: 91/459 | Training loss: 0.6614 | accuracy: 0.7500\n",
      "Batch: 182/459 | Training loss: 0.2090 | accuracy: 0.8750\n",
      "Batch: 273/459 | Training loss: 0.1511 | accuracy: 1.0000\n",
      "Batch: 364/459 | Training loss: 0.0905 | accuracy: 1.0000\n",
      "Batch: 455/459 | Training loss: 0.3530 | accuracy: 0.8750\n",
      "Epoch: 6 | Train Loss: 0.2835 | Train Acc: 0.8859\n",
      "Epoch time elapsed: 00:00:42.85\n",
      "\n",
      "Batch: 91/459 | Training loss: 0.1660 | accuracy: 0.8750\n",
      "Batch: 182/459 | Training loss: 0.2544 | accuracy: 0.8750\n",
      "Batch: 273/459 | Training loss: 0.2294 | accuracy: 1.0000\n",
      "Batch: 364/459 | Training loss: 0.1871 | accuracy: 0.8750\n",
      "Batch: 455/459 | Training loss: 0.0745 | accuracy: 1.0000\n",
      "Epoch: 7 | Train Loss: 0.2469 | Train Acc: 0.9047\n",
      "Epoch time elapsed: 00:00:43.35\n",
      "\n",
      "Batch: 91/459 | Training loss: 0.2879 | accuracy: 0.8750\n",
      "Batch: 182/459 | Training loss: 0.0601 | accuracy: 1.0000\n",
      "Batch: 273/459 | Training loss: 0.0658 | accuracy: 1.0000\n",
      "Batch: 364/459 | Training loss: 0.3203 | accuracy: 0.7500\n",
      "Batch: 455/459 | Training loss: 0.0844 | accuracy: 1.0000\n",
      "Epoch: 8 | Train Loss: 0.2032 | Train Acc: 0.9213\n",
      "Epoch time elapsed: 00:00:44.39\n",
      "\n",
      "Batch: 91/459 | Training loss: 0.1161 | accuracy: 1.0000\n",
      "Batch: 182/459 | Training loss: 0.0406 | accuracy: 1.0000\n",
      "Batch: 273/459 | Training loss: 0.0731 | accuracy: 1.0000\n",
      "Batch: 364/459 | Training loss: 0.7731 | accuracy: 0.6250\n",
      "Batch: 455/459 | Training loss: 0.0682 | accuracy: 1.0000\n",
      "Epoch: 9 | Train Loss: 0.1682 | Train Acc: 0.9365\n",
      "Epoch time elapsed: 00:00:45.32\n",
      "\n",
      "Batch: 91/459 | Training loss: 0.3133 | accuracy: 0.8750\n",
      "Batch: 182/459 | Training loss: 0.1040 | accuracy: 1.0000\n",
      "Batch: 273/459 | Training loss: 0.0533 | accuracy: 1.0000\n",
      "Batch: 364/459 | Training loss: 0.1463 | accuracy: 1.0000\n",
      "Batch: 455/459 | Training loss: 0.0782 | accuracy: 1.0000\n",
      "Epoch: 10 | Train Loss: 0.1463 | Train Acc: 0.9436\n",
      "Epoch time elapsed: 00:00:44.01\n",
      "\n",
      "Batch: 91/459 | Training loss: 0.0660 | accuracy: 1.0000\n",
      "Batch: 182/459 | Training loss: 0.0962 | accuracy: 1.0000\n",
      "Batch: 273/459 | Training loss: 0.0053 | accuracy: 1.0000\n",
      "Batch: 364/459 | Training loss: 0.0305 | accuracy: 1.0000\n",
      "Batch: 455/459 | Training loss: 0.0156 | accuracy: 1.0000\n",
      "Epoch: 11 | Train Loss: 0.1178 | Train Acc: 0.9581\n",
      "Epoch time elapsed: 00:00:42.92\n",
      "\n",
      "Batch: 91/459 | Training loss: 0.0921 | accuracy: 1.0000\n",
      "Batch: 182/459 | Training loss: 0.0537 | accuracy: 1.0000\n",
      "Batch: 273/459 | Training loss: 0.2534 | accuracy: 0.8750\n",
      "Batch: 364/459 | Training loss: 0.1340 | accuracy: 0.8750\n",
      "Batch: 455/459 | Training loss: 0.0436 | accuracy: 1.0000\n",
      "Epoch: 12 | Train Loss: 0.1005 | Train Acc: 0.9589\n",
      "Epoch time elapsed: 00:00:44.09\n",
      "\n",
      "Batch: 91/459 | Training loss: 0.1495 | accuracy: 1.0000\n",
      "Batch: 182/459 | Training loss: 0.0661 | accuracy: 1.0000\n",
      "Batch: 273/459 | Training loss: 0.0189 | accuracy: 1.0000\n",
      "Batch: 364/459 | Training loss: 0.0679 | accuracy: 1.0000\n",
      "Batch: 455/459 | Training loss: 0.0071 | accuracy: 1.0000\n",
      "Epoch: 13 | Train Loss: 0.0842 | Train Acc: 0.9714\n",
      "Epoch time elapsed: 00:00:42.96\n",
      "\n",
      "Batch: 91/459 | Training loss: 0.0401 | accuracy: 1.0000\n",
      "Batch: 182/459 | Training loss: 0.2561 | accuracy: 0.8750\n",
      "Batch: 273/459 | Training loss: 0.0121 | accuracy: 1.0000\n",
      "Batch: 364/459 | Training loss: 0.0072 | accuracy: 1.0000\n",
      "Batch: 455/459 | Training loss: 0.0897 | accuracy: 1.0000\n",
      "Epoch: 14 | Train Loss: 0.0714 | Train Acc: 0.9749\n",
      "Epoch time elapsed: 00:00:44.25\n",
      "\n",
      "Batch: 91/459 | Training loss: 0.1117 | accuracy: 0.8750\n",
      "Batch: 182/459 | Training loss: 0.2244 | accuracy: 0.8750\n",
      "Batch: 273/459 | Training loss: 0.1770 | accuracy: 0.8750\n",
      "Batch: 364/459 | Training loss: 0.0179 | accuracy: 1.0000\n",
      "Batch: 455/459 | Training loss: 0.0050 | accuracy: 1.0000\n",
      "Epoch: 15 | Train Loss: 0.0679 | Train Acc: 0.9747\n",
      "Epoch time elapsed: 00:00:43.72\n",
      "\n",
      "Batch: 91/459 | Training loss: 0.0123 | accuracy: 1.0000\n",
      "Batch: 182/459 | Training loss: 0.1077 | accuracy: 0.8750\n",
      "Batch: 273/459 | Training loss: 0.0395 | accuracy: 1.0000\n",
      "Batch: 364/459 | Training loss: 0.0147 | accuracy: 1.0000\n",
      "Batch: 455/459 | Training loss: 0.0082 | accuracy: 1.0000\n",
      "Epoch: 16 | Train Loss: 0.0538 | Train Acc: 0.9828\n",
      "Epoch time elapsed: 00:00:43.91\n",
      "\n",
      "Batch: 91/459 | Training loss: 0.2619 | accuracy: 0.8750\n",
      "Batch: 182/459 | Training loss: 0.2749 | accuracy: 0.8750\n",
      "Batch: 273/459 | Training loss: 0.1956 | accuracy: 0.8750\n",
      "Batch: 364/459 | Training loss: 0.0029 | accuracy: 1.0000\n",
      "Batch: 455/459 | Training loss: 0.2224 | accuracy: 0.8750\n",
      "Epoch: 17 | Train Loss: 0.0594 | Train Acc: 0.9771\n",
      "Epoch time elapsed: 00:00:44.06\n",
      "\n",
      "Batch: 91/459 | Training loss: 0.0008 | accuracy: 1.0000\n",
      "Batch: 182/459 | Training loss: 0.0025 | accuracy: 1.0000\n",
      "Batch: 273/459 | Training loss: 0.0101 | accuracy: 1.0000\n",
      "Batch: 364/459 | Training loss: 0.0646 | accuracy: 1.0000\n",
      "Batch: 455/459 | Training loss: 0.0973 | accuracy: 0.8750\n",
      "Epoch: 18 | Train Loss: 0.0365 | Train Acc: 0.9886\n",
      "Epoch time elapsed: 00:00:43.30\n",
      "\n",
      "Batch: 91/459 | Training loss: 0.0012 | accuracy: 1.0000\n",
      "Batch: 182/459 | Training loss: 0.0207 | accuracy: 1.0000\n",
      "Batch: 273/459 | Training loss: 0.0007 | accuracy: 1.0000\n",
      "Batch: 364/459 | Training loss: 0.0388 | accuracy: 1.0000\n",
      "Batch: 455/459 | Training loss: 0.2447 | accuracy: 0.8750\n",
      "Epoch: 19 | Train Loss: 0.0360 | Train Acc: 0.9891\n",
      "Epoch time elapsed: 00:00:45.23\n",
      "\n",
      "Batch: 91/459 | Training loss: 0.0253 | accuracy: 1.0000\n",
      "Batch: 182/459 | Training loss: 0.0287 | accuracy: 1.0000\n",
      "Batch: 273/459 | Training loss: 0.0005 | accuracy: 1.0000\n",
      "Batch: 364/459 | Training loss: 0.0203 | accuracy: 1.0000\n",
      "Batch: 455/459 | Training loss: 0.2045 | accuracy: 0.8750\n",
      "Epoch: 20 | Train Loss: 0.0361 | Train Acc: 0.9864\n",
      "Epoch time elapsed: 00:00:44.43\n",
      "\n",
      "Average time per epoch: 00:00:44.22\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from torch.nn import functional as F\n",
    "\n",
    "def get_accuracy(y_pred, targets):\n",
    "    predictions = torch.log_softmax(y_pred, dim=1).argmax(dim=1)\n",
    "    accuracy = (predictions == targets).sum() / len(targets)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def train(model, train_loader, val_loader, epochs, optimizer):\n",
    "    total_time = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        interval = len(train_loader) // 5\n",
    "\n",
    "        total_train_loss = 0\n",
    "        total_train_acc = 0\n",
    "        total_val_loss = 0\n",
    "        total_val_acc = 0\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        model.train()\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids, attention_mask=attention_mask, \n",
    "            )\n",
    "\n",
    "            #loss = loss_function(outputs, labels)\n",
    "            loss = loss_function(outputs.logits, labels)\n",
    "            acc = get_accuracy(outputs.logits, labels)\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "            total_train_acc += acc.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (batch_idx + 1) % interval == 0:\n",
    "                print(\n",
    "                    \"Batch: %s/%s | Training loss: %.4f | accuracy: %.4f\"\n",
    "                    % (batch_idx + 1, len(train_loader), loss, acc)\n",
    "                )\n",
    "\n",
    "        train_loss = total_train_loss / len(train_loader)\n",
    "        train_acc = total_train_acc / len(train_loader)\n",
    "\n",
    "        end = time.time()\n",
    "        hours, remainder = divmod(end - start, 3600)\n",
    "        minutes, seconds = divmod(remainder, 60)\n",
    "\n",
    "        print(f\"Epoch: {epoch+1} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "        #print(f\"Epoch: {epoch+1} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "        print(\n",
    "            \"Epoch time elapsed: {:0>2}:{:0>2}:{:05.2f}\".format(\n",
    "                int(hours), int(minutes), seconds\n",
    "            )\n",
    "        )\n",
    "        print(\"\")\n",
    "\n",
    "        total_time += end - start\n",
    "\n",
    "    # Get the average time per epoch\n",
    "    average_time_per_epoch = total_time / epochs\n",
    "    hours, remainder = divmod(average_time_per_epoch, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "\n",
    "    print(\n",
    "        \"Average time per epoch: {:0>2}:{:0>2}:{:05.2f}\".format(\n",
    "            int(hours), int(minutes), seconds\n",
    "        )\n",
    "    )\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr = 1e-5)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "train(model, train_dataloader, val_dataloader, 20, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d037c495-ed9c-4d3f-ad4b-5d57b210df13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 10/51 | Test loss: 0.7649 | accuracy: 0.8750\n",
      "Batch: 20/51 | Test loss: 1.6647 | accuracy: 0.6250\n",
      "Batch: 30/51 | Test loss: 2.0784 | accuracy: 0.6250\n",
      "Batch: 40/51 | Test loss: 0.7182 | accuracy: 0.7500\n",
      "Batch: 50/51 | Test loss: 0.0001 | accuracy: 1.0000\n",
      "Test loss: 1.0370 acc: 0.7990\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    interval = len(test_loader) // 5\n",
    "\n",
    "    total_test_loss = 0\n",
    "    total_test_acc = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_loader):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids, attention_mask=attention_mask, \n",
    "            )\n",
    "            loss = loss_function(outputs.logits, labels)\n",
    "            acc = get_accuracy(outputs.logits, labels)\n",
    "\n",
    "            total_test_loss += loss.item()\n",
    "            total_test_acc += acc.item()\n",
    "\n",
    "            if (batch_idx + 1) % interval == 0:\n",
    "                print(\n",
    "                    \"Batch: %s/%s | Test loss: %.4f | accuracy: %.4f\"\n",
    "                    % (batch_idx + 1, len(test_loader), loss, acc)\n",
    "                )\n",
    "\n",
    "    test_loss = total_test_loss / len(test_loader)\n",
    "    test_acc = total_test_acc / len(test_loader)\n",
    "\n",
    "    print(f\"Test loss: {test_loss:.4f} acc: {test_acc:.4f}\")\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "evaluate(model, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faf8114-6de2-4a9a-af26-0835d4cacd17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
