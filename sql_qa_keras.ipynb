{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e2e0bab-fae5-47bb-9138-5f2306a8d18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5506e09c-78d1-4ac2-b3e0-557e8e76c470",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load a dataset\n",
    "dataset = load_dataset('b-mc2/sql-create-context')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97c2e136-3732-4b8a-9687-417d695849f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = [example['context'] for example in dataset['train']]\n",
    "answers = [example['answer'] for example in dataset['train']]\n",
    "questions = [example['question'] for example in dataset['train']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b765afe-7f89-4e25-a3e5-0010b211fbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming contexts, answers, and questions are your dataset\n",
    "data = list(zip(contexts, answers, questions))\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Unzip the data\n",
    "train_contexts, train_answers, train_questions = map(list, zip(*train_data))\n",
    "val_contexts, val_answers, val_questions = map(list, zip(*val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a7809b4-07e4-4fac-9d93-be9d1b1eed3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def prepare_text(text):\n",
    "    text = '<START>' + text + '<END>'\n",
    "    return text\n",
    "\n",
    "train_answers = list(map(prepare_text, train_answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30a4b82b-4998-4e06-8722-f9bebb9a3975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer, trainers, models, pre_tokenizers, decoders, processors\n",
    "import tensorflow as tf\n",
    "\n",
    "# Initialize a tokenizer\n",
    "tokenizer = Tokenizer(models.BPE())\n",
    "\n",
    "# Set padding token. Padding token must be zero.\n",
    "tokenizer.add_special_tokens([\"<PAD>\", \"<START>\", \"<END>\"])\n",
    "tokenizer.enable_padding(pad_id=0, pad_token=\"<PAD>\")\n",
    "\n",
    "# Gather all texts\n",
    "all_texts = train_contexts + train_questions + train_answers\n",
    "\n",
    "# Train the tokenizer\n",
    "tokenizer.train_from_iterator(all_texts)\n",
    "\n",
    "# Now you can use the tokenizer to encode your texts\n",
    "prompt_tokens, answer_tokens = [], []\n",
    "for context, question, answer in zip(train_contexts, train_questions, train_answers):\n",
    "    prompt = question + \" context: \" + context\n",
    "    prompt_tokens.append(tokenizer.encode(prompt).ids)\n",
    "    answer_tokens.append(tokenizer.encode(answer).ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d759f44-1557-4e6f-a070-adeff5a345e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"<END>\").ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6440a4cd-cf72-4fa7-a921-a7bb680aed47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.9433e+04, 1.9802e+04, 3.1700e+03, 3.7200e+02, 6.8000e+01,\n",
       "        1.1000e+01, 0.0000e+00, 3.0000e+00, 0.0000e+00, 2.0000e+00]),\n",
       " array([  7. ,  19.4,  31.8,  44.2,  56.6,  69. ,  81.4,  93.8, 106.2,\n",
       "        118.6, 131. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_lengths = [len(seq) for seq in prompt_tokens]\n",
    "plt.hist(seq_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bbf7d4f-a298-4dba-b2b4-d3609c89e462",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_seq_length = 50  # replace with your desired sequence length\n",
    "answer_seq_length = 50\n",
    "\n",
    "# Add padding if necessary\n",
    "prompt_tokens_padded = tf.keras.preprocessing.sequence.pad_sequences(prompt_tokens, maxlen=prompt_seq_length, padding='post', value=0)\n",
    "answer_tokens_padded = tf.keras.preprocessing.sequence.pad_sequences(answer_tokens, maxlen=answer_seq_length, padding='post', value=0)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c9c1af10-ee4b-40c5-bb81-7c06851c35c2",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "from keras_nlp import layers\n",
    "\n",
    "def create_transformer(num_encoders=2, num_decoders=3):\n",
    "    # Define the input layers\n",
    "    encoder_inputs = tf.keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
    "    decoder_inputs = tf.keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
    "\n",
    "    # Define the embedding layer\n",
    "    embedding_layer = layers.TokenAndPositionEmbedding(\n",
    "        max_length, vocab_size, embed_dim)\n",
    "    encoder_embeddings = embedding_layer(encoder_inputs)\n",
    "    decoder_embeddings = embedding_layer(decoder_inputs)\n",
    "\n",
    "    # Define the encoder layers\n",
    "    encoder = layers.TransformerEncoder(embed_dim, num_heads, ff_dim)\n",
    "    for _ in range(num_encoders):\n",
    "        encoder_outputs = encoder(encoder_embeddings)\n",
    "\n",
    "    # Define the decoder layers\n",
    "    decoder = layers.TransformerDecoder(embed_dim, num_heads, ff_dim)\n",
    "    for _ in range(num_decoders):\n",
    "        decoder_outputs = decoder([decoder_embeddings, encoder_outputs])\n",
    "\n",
    "    # Define the output layer\n",
    "    outputs = layers.Dense(vocab_size, activation=\"softmax\")(decoder_outputs)\n",
    "    model = tf.keras.Model([encoder_inputs, decoder_inputs], outputs)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Define your parameters\n",
    "max_length = 200\n",
    "vocab_size = 20000\n",
    "embed_dim = 256\n",
    "num_heads = 8\n",
    "ff_dim = 512\n",
    "\n",
    "# Create your model\n",
    "model = create_transformer(num_encoders=2, num_decoders=3)\n",
    "model.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a71466a-e060-4fa1-9414-0b290ddf8ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-23 20:04:36.676076: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Max\n",
      "2024-05-23 20:04:36.676098: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 64.00 GB\n",
      "2024-05-23 20:04:36.676102: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 24.00 GB\n",
      "2024-05-23 20:04:36.676128: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-05-23 20:04:36.676140: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "________________________________________________________________________________________________________________________\n",
      " Layer (type)                       Output Shape                        Param #     Connected to                        \n",
      "========================================================================================================================\n",
      " encoder_input (InputLayer)         [(None, None)]                      0           []                                  \n",
      "                                                                                                                        \n",
      " decoder_input (InputLayer)         [(None, None)]                      0           []                                  \n",
      "                                                                                                                        \n",
      " embedding (Embedding)              (None, None, 64)                    1920128     ['encoder_input[0][0]']             \n",
      "                                                                                                                        \n",
      " embedding_1 (Embedding)            (None, None, 64)                    1920128     ['decoder_input[0][0]']             \n",
      "                                                                                                                        \n",
      " position_embedding (PositionEmbed  (None, None, 64)                    3200        ['embedding[0][0]']                 \n",
      " ding)                                                                                                                  \n",
      "                                                                                                                        \n",
      " position_embedding_1 (PositionEmb  (None, None, 64)                    3200        ['embedding_1[0][0]']               \n",
      " edding)                                                                                                                \n",
      "                                                                                                                        \n",
      " add (Add)                          (None, None, 64)                    0           ['embedding[0][0]',                 \n",
      "                                                                                     'position_embedding[0][0]']        \n",
      "                                                                                                                        \n",
      " add_1 (Add)                        (None, None, 64)                    0           ['embedding_1[0][0]',               \n",
      "                                                                                     'position_embedding_1[0][0]']      \n",
      "                                                                                                                        \n",
      " transformer_encoder (TransformerE  (None, None, 64)                    83008       ['add[0][0]']                       \n",
      " ncoder)                                                                                                                \n",
      "                                                                                                                        \n",
      " transformer_decoder (TransformerD  (None, None, 64)                    99776       ['add_1[0][0]',                     \n",
      " ecoder)                                                                             'transformer_encoder[0][0]']       \n",
      "                                                                                                                        \n",
      " dropout_2 (Dropout)                (None, None, 64)                    0           ['transformer_decoder[0][0]']       \n",
      "                                                                                                                        \n",
      " dense (Dense)                      (None, None, 30002)                 1950130     ['dropout_2[0][0]']                 \n",
      "                                                                                                                        \n",
      "========================================================================================================================\n",
      "Total params: 5979570 (22.81 MB)\n",
      "Trainable params: 5979570 (22.81 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Embedding\n",
    "from keras_nlp.layers import ReversibleEmbedding, PositionEmbedding, TransformerEncoder, TransformerDecoder\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "sequence_length = 50\n",
    "vocab_size = tokenizer.get_vocab_size()\n",
    "num_heads = 8\n",
    "embedding_dim = 64\n",
    "feedforward_dim = 512\n",
    "\n",
    "encoder_input = Input(shape=(None,), dtype='int64', name='encoder_input')\n",
    "encoder_token_embeddings = Embedding(input_dim=vocab_size, output_dim=embedding_dim, mask_zero=True)(encoder_input)\n",
    "encoder_position_embeddings = PositionEmbedding(sequence_length=sequence_length)(encoder_token_embeddings)\n",
    "encoder_embeddings = tf.keras.layers.Add()([encoder_token_embeddings, encoder_position_embeddings])\n",
    "encoder_output = TransformerEncoder(feedforward_dim, num_heads)(encoder_embeddings)\n",
    "\n",
    "decoder_input = Input(shape=(None,), dtype='int64', name='decoder_input')\n",
    "decoder_token_embeddings = Embedding(input_dim=vocab_size, output_dim=embedding_dim, mask_zero=True)(decoder_input)\n",
    "decoder_position_embeddings = PositionEmbedding(sequence_length=sequence_length)(decoder_token_embeddings)\n",
    "decoder_embeddings = tf.keras.layers.Add()([decoder_token_embeddings, decoder_position_embeddings])\n",
    "decoder_output = TransformerDecoder(feedforward_dim, num_heads)(decoder_embeddings, encoder_output)\n",
    "decoder_output = Dropout(0.4)(decoder_output)\n",
    "\n",
    "final_output = Dense(vocab_size, activation='softmax')(decoder_output)\n",
    "model = Model([encoder_input, decoder_input], final_output)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary(line_length=120)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29b1cdf2-88db-43a6-81d1-3263ed44dc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = { 'encoder_input': prompt_tokens_padded, 'decoder_input': answer_tokens_padded[:, :-1] }\n",
    "outputs = answer_tokens_padded[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bdb628f-235e-476d-a574-eb82135f4354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-23 20:04:39.020445: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1572/1572 [==============================] - ETA: 0s - loss: 5.5284 - accuracy: 0.3125\n",
      "Epoch 1: val_accuracy improved from -inf to 0.34715, saving model to model/sql_qa_model.keras\n",
      "1572/1572 [==============================] - 118s 73ms/step - loss: 5.5284 - accuracy: 0.3125 - val_loss: 4.5934 - val_accuracy: 0.3472\n",
      "Epoch 2/20\n",
      " 464/1572 [=======>......................] - ETA: 1:11 - loss: 4.4659 - accuracy: 0.3533"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m callback_es \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m callback_mc \u001b[38;5;241m=\u001b[39m ModelCheckpoint(checkpoint_filepath, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcallback_es\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback_mc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ibox/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/ibox/lib/python3.11/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/ibox/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/ibox/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/ibox/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/ibox/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ibox/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/ibox/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/ibox/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/ibox/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/envs/ibox/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "checkpoint_filepath = 'model/sql_qa_model.keras'\n",
    "callback_es = EarlyStopping(monitor='val_accuracy', restore_best_weights=True)\n",
    "callback_mc = ModelCheckpoint(checkpoint_filepath, monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "history = model.fit(inputs, outputs, epochs=20, validation_split=0.2, callbacks=[callback_es, callback_mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "177e918a-8598-4831-b438-7c0fdb6b3bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"model/sql_qa_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "525ba61c-0b2c-4b69-ae39-968fcb9a1d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bot_answer(text, model, tokenizer, sequence_length):\n",
    "\n",
    "    text_encoded = tokenizer.encode(text)\n",
    "    encoder_input = text_encoded.ids\n",
    "    encoder_input = tf.keras.preprocessing.sequence.pad_sequences([encoder_input], maxlen=sequence_length, padding='post', value=0)\n",
    "    encoder_input = tf.convert_to_tensor(encoder_input)\n",
    "    encoder_input = tf.reshape(encoder_input, (1, 50))\n",
    "    \n",
    "    decoded_text = '<START>'\n",
    "    for i in range(sequence_length):\n",
    "        decoder_input = tokenizer.encode(decoded_text).ids\n",
    "        decoder_input = tf.keras.preprocessing.sequence.pad_sequences([decoder_input], maxlen=sequence_length, padding='post', value=0)\n",
    "        decoder_input = tf.convert_to_tensor(decoder_input)\n",
    "        decoder_input = tf.reshape(decoder_input, (1, 50))\n",
    "    \n",
    "        prediction = model([encoder_input, decoder_input])\n",
    "    \n",
    "        idx = np.argmax(prediction[0, i, :])\n",
    "        token = tokenizer.decode([idx])\n",
    "        decoded_text += token\n",
    "\n",
    "        #if token == '<END>':\n",
    "        #    break\n",
    "\n",
    "    return decoded_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c196d09-6942-4981-b530-d71711b49e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62861, 50)\n",
      "(62861, 49)\n",
      "(62861, 49)\n"
     ]
    }
   ],
   "source": [
    "print (inputs['encoder_input'].shape)\n",
    "print (inputs['decoder_input'].shape)\n",
    "print (outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "850cc2dd-014a-4b7f-ab21-d4d57e9f6bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction = model([inputs['encoder_input'][0:10], inputs['decoder_input'][0:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd1fe69e-9439-4af8-9176-e89b19b5ff3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What was the number of Laps with a Grid of more than 3 and Time of 39:24.967? context: CREATE TABLE table_name_8 (laps INTEGER, grid VARCHAR, time VARCHAR)\n",
      "<START>SELECT23 WHERE t = \"\" AND  = \"\" AND  = \"446622\"7224\"212\"2\"\"2\"2\"\"\"\"\"\"\n",
      "SELECT MIN(laps) FROM table_name_8 WHERE grid > 3 AND time = \"39:24.967\"\n",
      "-------------\n",
      "Which Senior status has a Chief Judge of , a Reason for termination of death, and Active service of 19671983? context: CREATE TABLE table_name_18 (senior_status VARCHAR, active_service VARCHAR, chief_judge VARCHAR, reason_for_termination VARCHAR)\n",
      "<START>SELECT205s) FROM table__4 WHERE  = \"\" AND s = \"s = \"\" AND >  AS T2 ON T1.< 64> 64\n",
      "SELECT senior_status FROM table_name_18 WHERE chief_judge = \"\" AND reason_for_termination = \"death\" AND active_service = \"19671983\"\n",
      "-------------\n",
      "Which Rank has a Reaction of 0.198, and a Time smaller than 46.3? context: CREATE TABLE table_name_98 (rank INTEGER, react VARCHAR, time VARCHAR)\n",
      "<START>SELECT\") FROM table_28 WHERE t = \"\" AND  = \"\" AND < 22\n",
      "SELECT MAX(rank) FROM table_name_98 WHERE react = 0.198 AND time < 46.3\n",
      "-------------\n",
      "Who narrated when the vessel operator is de beers? context: CREATE TABLE table_26168687_3 (narrated_by VARCHAR, vessel_operator VARCHAR)\n",
      "<START>SELECT23________s) FROM table_name_s) FROM table_name_s) FROM table_name_ = \n",
      "SELECT narrated_by FROM table_26168687_3 WHERE vessel_operator = \"De Beers\"\n",
      "-------------\n",
      "What's the original season in 11th place? context: CREATE TABLE table_name_15 (original_season VARCHAR, placing VARCHAR)\n",
      "<START>SELECTs FROM table_name_) FROM table_2 WHERE t = \"\" AND  = \n",
      "SELECT original_season FROM table_name_15 WHERE placing = \"11th place\"\n",
      "-------------\n",
      "What is the Place of the Song by Artist Rosie Hunter with a Draw of 1 or larger? context: CREATE TABLE table_name_10 (place VARCHAR, artist VARCHAR, draw VARCHAR)\n",
      "<START>SELECT\") FROM table_name_) FROM table_name_ WHERE team = \"\" AND  = \"\" AND < \n",
      "SELECT COUNT(place) FROM table_name_10 WHERE artist = \"rosie hunter\" AND draw > 1\n",
      "-------------\n",
      "Show the times of elimination by \"Punk\" or \"Orton\". context: CREATE TABLE elimination (TIME VARCHAR, Eliminated_By VARCHAR)\n",
      "<START>SELECT T1. T1. FROM  FROM  AS T1 JOIN  AS T2 ON T1. AS T2 ON T1. AS T2 ON T1. AS T2 ON T1. AS T2 ON T1. AS T2 ON T1. AS T2 ON T1.id = T2.id = T2.id = T2. AS T2 ON T1.id = T2. AS T2 ON T1. AS T2 ON T1.id = T2. AS T2 ON T1.ORDER BY COUNT(*) DESC LIMIT  AS T2 ON T1.ORDER BY COUNT(*) DESC LIMIT  AS T2 ON T1. AS T2 ON T1.ORDER BY COUNT(*) DESC LIMIT  AS T2 ON T1.\n",
      "SELECT TIME FROM elimination WHERE Eliminated_By = \"Punk\" OR Eliminated_By = \"Orton\"\n",
      "-------------\n",
      "Where did they play the San Diego Chargers? context: CREATE TABLE table_13259009_2 (game_site VARCHAR, opponent VARCHAR)\n",
      "<START>SELECTs FROM table_ WHERE t WHERE t = \"\" AND  = \n",
      "SELECT game_site FROM table_13259009_2 WHERE opponent = \"San Diego Chargers\"\n",
      "-------------\n",
      "Which Played has a Lost larger than 2, and a Team of amrica? context: CREATE TABLE table_name_4 (played VARCHAR, lost VARCHAR, team VARCHAR)\n",
      "<START>SELECT\") FROM table_name_) FROM table_134_9 WHERE  = \"\" AND  = \"\"\"\"\"\"\"\"\"\"\"\"\n",
      "SELECT played FROM table_name_4 WHERE lost > 2 AND team = \"amrica\"\n",
      "-------------\n",
      "What venue has a score of 4-0 with the 2002 Tiger Cup listed as the competition? context: CREATE TABLE table_name_26 (venue VARCHAR, score VARCHAR, competition VARCHAR)\n",
      "<START>SELECT\"away_team = \"\"\"away_team = \"away_team = \"away_team\"2\"\"\"\n",
      "SELECT venue FROM table_name_26 WHERE score = \"4-0\" AND competition = \"2002 tiger cup\"\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    question = val_questions[i]\n",
    "    context = val_contexts[i]\n",
    "    answer = val_answers[i]\n",
    "    prompt = question + \" context: \" + context\n",
    "    print (prompt)\n",
    "    decoded_text = get_bot_answer(prompt, model, tokenizer, sequence_length)\n",
    "    print (decoded_text)\n",
    "    print (answer)\n",
    "    print (\"-------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc7422f-63de-4bad-937d-6aba406849ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
