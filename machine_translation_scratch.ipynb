{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c76ee634-a92e-4ef4-8fe3-f006f42f728b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55010993-1a92-4c5c-9f56-3ae79494b952",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a41e9d8-703d-4c9b-afde-28ae6412f1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-21 16:28:25.864218: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Max\n",
      "2024-05-21 16:28:25.864234: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 64.00 GB\n",
      "2024-05-21 16:28:25.864239: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 24.00 GB\n",
      "2024-05-21 16:28:25.864264: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-05-21 16:28:25.864278: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en',\n",
    "                               with_info=True,\n",
    "                               as_supervised=True)\n",
    "\n",
    "train_examples, val_examples = examples['train'], examples['validation']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1db7fa-fbca-405b-b046-da68b6cc13a0",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69738f66-f409-4cac-b127-90ac5a905026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the tokenizer on your text\n",
    "pt_sentences = []\n",
    "en_sentences = []\n",
    "\n",
    "for pt, en in train_examples:\n",
    "    pt_sentences.append(pt.numpy().decode('utf-8'))\n",
    "    en_sentences.append(en.numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da28e0b8-9d55-43d4-b6e6-932ff0afda26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Vocabulary Size:  30000\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer, models, pre_tokenizers, decoders, processors\n",
    "\n",
    "sequence_len = 50\n",
    "\n",
    "# Initialize a tokenizer\n",
    "tokenizer = Tokenizer(models.BPE())\n",
    "\n",
    "# Customize pre-tokenization and decoding\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=True)\n",
    "tokenizer.decoder = decoders.ByteLevel()\n",
    "\n",
    "# Enable padding\n",
    "tokenizer.enable_padding(pad_id=0, pad_token=\"[PAD]\", length=sequence_len)\n",
    "\n",
    "# Enable truncation\n",
    "tokenizer.enable_truncation(max_length=sequence_len)\n",
    "\n",
    "# Fit the tokenizer on your text\n",
    "tokenizer.train_from_iterator(pt_sentences + en_sentences)\n",
    "\n",
    "# Get vocab size\n",
    "vocab_size = tokenizer.get_vocab_size()\n",
    "print('Vocabulary Size: ', vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49984ac9-9b08-4ae8-8022-549a43567e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_tokens = []\n",
    "en_tokens = []\n",
    "\n",
    "for pt, en in train_examples:\n",
    "  pt = pt.numpy().decode('utf-8')\n",
    "  en = en.numpy().decode('utf-8')\n",
    "\n",
    "  # Encode the sentences\n",
    "  pt_encoded = tokenizer.encode(pt)\n",
    "  en_encoded = tokenizer.encode(en)\n",
    "\n",
    "  # Get the tokens\n",
    "  pt_tokens.append(pt_encoded.ids)\n",
    "  en_tokens.append(en_encoded.ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17858b63-dd51-44aa-888b-ccfffeeb9beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' e , pelos vistos , o grande profeta de um caso de violência é um caso precedente de violência .!!!!!!!!!!!!!!!!!!!!!!!!!!!!'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(pt_tokens[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93e4c70f-532f-4298-a1bb-35815452bc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_tokens = tf.convert_to_tensor(pt_tokens)\n",
    "en_tokens = tf.convert_to_tensor(en_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9ee793e-1a86-4f29-a646-7ebdd577cf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = { 'encoder_input': pt_tokens, 'decoder_input': en_tokens[:, :-1] }\n",
    "outputs = en_tokens[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da52e455-6293-414a-9075-5dcee4c14d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = tokenizer.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90ee662e-c63f-48c1-bfcd-257541dcdea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    \"\"\"Calculate the attention weights.\"\"\"\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "    # scale matmul_qk\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "    # add the mask to zero out padding tokens\n",
    "    if mask is not None:\n",
    "        logits += mask * -1e9\n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k)\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ae4c1b1-7087-4d56-bcc6-9e5242805ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    # (batch_size, 1, 1, sequence length)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a943211f-6371-4c48-8948-5c72cb264b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, **kwargs):\n",
    "        assert d_model % num_heads == 0\n",
    "        super(MultiHeadAttentionLayer, self).__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(MultiHeadAttentionLayer, self).get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                \"num_heads\": self.num_heads,\n",
    "                \"d_model\": self.d_model,\n",
    "            }\n",
    "        )\n",
    "        return config\n",
    "\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.keras.layers.Lambda(\n",
    "            lambda inputs: tf.reshape(\n",
    "                inputs, shape=(batch_size, -1, self.num_heads, self.depth)\n",
    "            )\n",
    "        )(inputs)\n",
    "        return tf.keras.layers.Lambda(\n",
    "            lambda inputs: tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "        )(inputs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = (\n",
    "            inputs[\"query\"],\n",
    "            inputs[\"key\"],\n",
    "            inputs[\"value\"],\n",
    "            inputs[\"mask\"],\n",
    "        )\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # linear layers\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        # split heads\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # scaled dot-product attention\n",
    "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "        scaled_attention = tf.keras.layers.Lambda(\n",
    "            lambda scaled_attention: tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "        )(scaled_attention)\n",
    "\n",
    "        # concatenation of heads\n",
    "        concat_attention = tf.keras.layers.Lambda(\n",
    "            lambda scaled_attention: tf.reshape(\n",
    "                scaled_attention, (batch_size, -1, self.d_model)\n",
    "            )\n",
    "        )(scaled_attention)\n",
    "\n",
    "        # final linear layer\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    attention = MultiHeadAttentionLayer(d_model, num_heads, name=\"attention\")(\n",
    "        {\"query\": inputs, \"key\": inputs, \"value\": inputs, \"mask\": padding_mask}\n",
    "    )\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    add_attention = tf.keras.layers.add([inputs, attention])\n",
    "    attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(add_attention)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation=\"relu\")(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    add_attention = tf.keras.layers.add([attention, outputs])\n",
    "    outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(add_attention)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d2e0a65-3427-4250-a043-3492183f19ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size, num_layers, units, d_model, num_heads, dropout, name=\"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.keras.layers.Lambda(\n",
    "        lambda d_model: tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    )(d_model)\n",
    "    #embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name=\"encoder_layer_{}\".format(i),\n",
    "        )([outputs, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b873965-af57-4688-8832-ec0930329a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "sample_encoder = encoder(\n",
    "    vocab_size=8192,\n",
    "    num_layers=2,\n",
    "    units=512,\n",
    "    d_model=128,\n",
    "    num_heads=4,\n",
    "    dropout=0.3,\n",
    "    name=\"sample_encoder\",\n",
    ")\n",
    "\n",
    "tf.keras.utils.plot_model(sample_encoder, to_file=\"encoder.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d8c58a8-32fa-4c68-b10a-f7e31c4d45e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    look_ahead_mask = tf.keras.Input(shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    attention1 = MultiHeadAttentionLayer(d_model, num_heads, name=\"attention_1\")(\n",
    "        inputs={\n",
    "            \"query\": inputs,\n",
    "            \"key\": inputs,\n",
    "            \"value\": inputs,\n",
    "            \"mask\": look_ahead_mask,\n",
    "        }\n",
    "    )\n",
    "    add_attention = tf.keras.layers.add([attention1, inputs])\n",
    "    attention1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(add_attention)\n",
    "\n",
    "    attention2 = MultiHeadAttentionLayer(d_model, num_heads, name=\"attention_2\")(\n",
    "        inputs={\n",
    "            \"query\": attention1,\n",
    "            \"key\": enc_outputs,\n",
    "            \"value\": enc_outputs,\n",
    "            \"mask\": padding_mask,\n",
    "        }\n",
    "    )\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    add_attention = tf.keras.layers.add([attention2, attention1])\n",
    "    attention2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(add_attention)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation=\"relu\")(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    add_attention = tf.keras.layers.add([outputs, attention2])\n",
    "    outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(add_attention)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28d01d3e-204c-4efa-8a0e-6d13ffcfdddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "sample_decoder_layer = decoder_layer(\n",
    "    units=512, d_model=128, num_heads=4, dropout=0.3, name=\"sample_decoder_layer\"\n",
    ")\n",
    "\n",
    "tf.keras.utils.plot_model(\n",
    "    sample_decoder_layer, to_file=\"decoder_layer.png\", show_shapes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "93309043-7081-4e52-bd15-06c0cac92d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size, num_layers, units, d_model, num_heads, dropout, name=\"decoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    look_ahead_mask = tf.keras.Input(shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.keras.layers.Lambda(\n",
    "        lambda d_model: tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    )(d_model)\n",
    "    #embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name=\"decoder_layer_{}\".format(i),\n",
    "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "        outputs=outputs,\n",
    "        name=name,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b851903d-f8e5-4ca3-b490-d48eda9223be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(\n",
    "    vocab_size, num_layers, units, d_model, num_heads, dropout, name=\"transformer\"\n",
    "):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None), name=\"enc_padding_mask\"\n",
    "    )(inputs)\n",
    "    # mask the future tokens for decoder inputs at the 1st attention block\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "        create_look_ahead_mask, output_shape=(1, None, None), name=\"look_ahead_mask\"\n",
    "    )(dec_inputs)\n",
    "    # mask the encoder outputs for the 2nd attention block\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None), name=\"dec_padding_mask\"\n",
    "    )(inputs)\n",
    "\n",
    "    enc_outputs = encoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "    dec_outputs = decoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c1935fd-2c81-41c3-9b37-de93670da83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(\n",
    "    vocab_size, num_layers, units, d_model, num_heads, dropout, name=\"transformer\"\n",
    "):\n",
    "    encoder_input = tf.keras.Input(shape=(None,), name=\"encoder_input\")\n",
    "    decoder_input = tf.keras.Input(shape=(None,), name=\"decoder_input\")\n",
    "\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None), name=\"enc_padding_mask\"\n",
    "    )(encoder_input)\n",
    "    # mask the future tokens for decoder inputs at the 1st attention block\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "        create_look_ahead_mask, output_shape=(1, None, None), name=\"look_ahead_mask\"\n",
    "    )(decoder_input)\n",
    "    # mask the encoder outputs for the 2nd attention block\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "        create_padding_mask, output_shape=(1, 1, None), name=\"dec_padding_mask\"\n",
    "    )(encoder_input)\n",
    "\n",
    "    enc_outputs = encoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )(inputs=[encoder_input, enc_padding_mask])\n",
    "\n",
    "    dec_outputs = decoder(\n",
    "        vocab_size=vocab_size,\n",
    "        num_layers=num_layers,\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "    )(inputs=[decoder_input, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs={'encoder_input': encoder_input, 'decoder_input': decoder_input}, outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "04794a67-fc9f-40c2-8cd4-bcbbc77d31e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum sentence length\n",
    "MAX_LENGTH = 40\n",
    "\n",
    "VOCAB_SIZE = 30000\n",
    "\n",
    "# Maximum number of samples to preprocess\n",
    "MAX_SAMPLES = 50000\n",
    "\n",
    "# For tf.data.Dataset\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# For Transformer\n",
    "NUM_LAYERS = 2\n",
    "D_MODEL = 256\n",
    "NUM_HEADS = 2\n",
    "UNITS = 512\n",
    "DROPOUT = 0.1\n",
    "\n",
    "EPOCHS = 40\n",
    "\n",
    "model = transformer(\n",
    "        vocab_size=VOCAB_SIZE,\n",
    "        num_layers=NUM_LAYERS,\n",
    "        units=UNITS,\n",
    "        d_model=D_MODEL,\n",
    "        num_heads=NUM_HEADS,\n",
    "        dropout=DROPOUT,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d5010669-be59-4ea5-956a-6ebdeefa212c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "________________________________________________________________________________________________________________________\n",
      " Layer (type)                       Output Shape                        Param #     Connected to                        \n",
      "========================================================================================================================\n",
      " encoder_input (InputLayer)         [(None, None)]                      0           []                                  \n",
      "                                                                                                                        \n",
      " decoder_input (InputLayer)         [(None, None)]                      0           []                                  \n",
      "                                                                                                                        \n",
      " enc_padding_mask (Lambda)          (None, 1, 1, None)                  0           ['encoder_input[0][0]']             \n",
      "                                                                                                                        \n",
      " encoder (Functional)               (None, None, 256)                   8734208     ['encoder_input[0][0]',             \n",
      "                                                                                     'enc_padding_mask[0][0]']          \n",
      "                                                                                                                        \n",
      " look_ahead_mask (Lambda)           (None, 1, None, None)               0           ['decoder_input[0][0]']             \n",
      "                                                                                                                        \n",
      " dec_padding_mask (Lambda)          (None, 1, 1, None)                  0           ['encoder_input[0][0]']             \n",
      "                                                                                                                        \n",
      " decoder (Functional)               (None, None, 256)                   9261568     ['decoder_input[0][0]',             \n",
      "                                                                                     'encoder[0][0]',                   \n",
      "                                                                                     'look_ahead_mask[0][0]',           \n",
      "                                                                                     'dec_padding_mask[0][0]']          \n",
      "                                                                                                                        \n",
      " outputs (Dense)                    (None, None, 30000)                 7710000     ['decoder[0][0]']                   \n",
      "                                                                                                                        \n",
      "========================================================================================================================\n",
      "Total params: 25705776 (98.06 MB)\n",
      "Trainable params: 25705776 (98.06 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary(line_length=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2ef02faf-a748-43f5-9ec0-fcadb7440936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding_10/embeddings:0\n",
      "attention/dense_98/kernel:0\n",
      "attention/dense_98/bias:0\n",
      "attention/dense_99/kernel:0\n",
      "attention/dense_99/bias:0\n",
      "attention/dense_100/kernel:0\n",
      "attention/dense_100/bias:0\n",
      "attention/dense_101/kernel:0\n",
      "attention/dense_101/bias:0\n",
      "layer_normalization_31/gamma:0\n",
      "layer_normalization_31/beta:0\n",
      "dense_102/kernel:0\n",
      "dense_102/bias:0\n",
      "dense_103/kernel:0\n",
      "dense_103/bias:0\n",
      "layer_normalization_32/gamma:0\n",
      "layer_normalization_32/beta:0\n",
      "attention/dense_104/kernel:0\n",
      "attention/dense_104/bias:0\n",
      "attention/dense_105/kernel:0\n",
      "attention/dense_105/bias:0\n",
      "attention/dense_106/kernel:0\n",
      "attention/dense_106/bias:0\n",
      "attention/dense_107/kernel:0\n",
      "attention/dense_107/bias:0\n",
      "layer_normalization_33/gamma:0\n",
      "layer_normalization_33/beta:0\n",
      "dense_108/kernel:0\n",
      "dense_108/bias:0\n",
      "dense_109/kernel:0\n",
      "dense_109/bias:0\n",
      "layer_normalization_34/gamma:0\n",
      "layer_normalization_34/beta:0\n",
      "embedding_11/embeddings:0\n",
      "attention_1/dense_110/kernel:0\n",
      "attention_1/dense_110/bias:0\n",
      "attention_1/dense_111/kernel:0\n",
      "attention_1/dense_111/bias:0\n",
      "attention_1/dense_112/kernel:0\n",
      "attention_1/dense_112/bias:0\n",
      "attention_1/dense_113/kernel:0\n",
      "attention_1/dense_113/bias:0\n",
      "layer_normalization_35/gamma:0\n",
      "layer_normalization_35/beta:0\n",
      "attention_2/dense_114/kernel:0\n",
      "attention_2/dense_114/bias:0\n",
      "attention_2/dense_115/kernel:0\n",
      "attention_2/dense_115/bias:0\n",
      "attention_2/dense_116/kernel:0\n",
      "attention_2/dense_116/bias:0\n",
      "attention_2/dense_117/kernel:0\n",
      "attention_2/dense_117/bias:0\n",
      "layer_normalization_36/gamma:0\n",
      "layer_normalization_36/beta:0\n",
      "dense_118/kernel:0\n",
      "dense_118/bias:0\n",
      "dense_119/kernel:0\n",
      "dense_119/bias:0\n",
      "layer_normalization_37/gamma:0\n",
      "layer_normalization_37/beta:0\n",
      "attention_1/dense_120/kernel:0\n",
      "attention_1/dense_120/bias:0\n",
      "attention_1/dense_121/kernel:0\n",
      "attention_1/dense_121/bias:0\n",
      "attention_1/dense_122/kernel:0\n",
      "attention_1/dense_122/bias:0\n",
      "attention_1/dense_123/kernel:0\n",
      "attention_1/dense_123/bias:0\n",
      "layer_normalization_38/gamma:0\n",
      "layer_normalization_38/beta:0\n",
      "attention_2/dense_124/kernel:0\n",
      "attention_2/dense_124/bias:0\n",
      "attention_2/dense_125/kernel:0\n",
      "attention_2/dense_125/bias:0\n",
      "attention_2/dense_126/kernel:0\n",
      "attention_2/dense_126/bias:0\n",
      "attention_2/dense_127/kernel:0\n",
      "attention_2/dense_127/bias:0\n",
      "layer_normalization_39/gamma:0\n",
      "layer_normalization_39/beta:0\n",
      "dense_128/kernel:0\n",
      "dense_128/bias:0\n",
      "dense_129/kernel:0\n",
      "dense_129/bias:0\n",
      "layer_normalization_40/gamma:0\n",
      "layer_normalization_40/beta:0\n",
      "outputs/kernel:0\n",
      "outputs/bias:0\n"
     ]
    }
   ],
   "source": [
    "for v in model.trainable_variables:\n",
    "    print(v.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cda3fb48-4a42-4480-b5db-4164cbaf9b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-21 17:06:49.063332: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1619/1619 [==============================] - 251s 150ms/step - loss: 5.8948 - accuracy: 0.6347\n",
      "Epoch 2/10\n",
      "1619/1619 [==============================] - 240s 148ms/step - loss: 5.8835 - accuracy: 0.6352\n",
      "Epoch 3/10\n",
      "1061/1619 [==================>...........] - ETA: 1:22 - loss: 5.8591 - accuracy: 0.6367"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ibox/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/ibox/lib/python3.11/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/ibox/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/ibox/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/ibox/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/ibox/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ibox/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/ibox/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/ibox/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/ibox/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/envs/ibox/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(inputs, outputs, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
